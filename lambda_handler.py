# lambda_function.py
from openai import OpenAI
from datetime import datetime, timedelta
import os
import urllib
import json
import boto3
import base64
import unicodedata
from enum import Enum
from typing import Optional, Dict, Any, Tuple, List
from twilio.rest import Client
from psycopg2 import pool
from contextlib import contextmanager
import atexit
import re
import time
import requests
import tempfile

# =========================
# Configura√ß√£o
# =========================
MODEL_NAME = os.getenv("OPENAI_MODEL", "o3-2025-04-16")
SCREENING_MODEL = os.getenv("SCREENING_MODEL", "gpt-4.1-nano-2025-04-14")  # Modelo para triagem inicial
OPENAI_API_KEY = os.environ["OPENAI_API_KEY"]
TWILIO_ACCOUNT_SID = os.environ["TWILIO_ACCOUNT_SID"]
TWILIO_AUTH_TOKEN = os.environ["TWILIO_AUTH_TOKEN"]
TWILIO_WHATSAPP_FROM = os.environ["TWILIO_WHATSAPP_FROM"]
S3_BUCKET = os.environ["S3_BUCKET"]

# Limiar de confian√ßa para acionar protocolo detalhado
SAFETY_CONFIDENCE_THRESHOLD = 0.4

# Configura√ß√µes de √°udio
MAX_AUDIO_DURATION_MULTIPLE_CHOICE = 15  # segundos
MAX_AUDIO_DURATION_TEXT = 120  # segundos (2 minutos)
MAX_AUDIO_DURATION_LIKERT = 15  # segundos

DB_CONFIG = {
    "host": os.environ["DB_HOST"],
    "port": int(os.getenv("DB_PORT", "5432")),
    "dbname": os.environ["DB_NAME"],
    "user": os.environ["DB_USER"],
    "password": os.environ["DB_PASSWORD"],
}

# Clientes
client = OpenAI(api_key=OPENAI_API_KEY)
s3 = boto3.client("s3")
twilio_client = Client(TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN)
lambda_client = boto3.client("lambda")

# Pool de conex√µes
db_pool = None

# Cache do question√°rio
_questionnaire_cache = None

# =========================
# Estados da M√°quina
# =========================
class State(Enum):
    WELCOME = "welcome"
    CONSENT = "consent"
    PHASE1_QUESTIONS = "phase1_questions"
    ASSESSMENT = "assessment"
    FOLLOWUP_INTRO = "followup_intro"
    FOLLOWUP_QUESTIONS = "followup_questions"
    ORIGIN_INTRO = "origin_intro"
    ORIGIN_QUESTIONS = "origin_questions"
    COMPLETION = "completion"
    EMERGENCY = "emergency"
    RESET = "reset"

# =========================
# Constantes de Follow-up
# =========================
FOLLOWUP_QUESTIONS = [
    {"id": "A1", "question": "J√° tive afastamento do trabalho por alguma causa psicossocial?", "options": ["Sim", "N√£o", "Prefiro n√£o responder"]},
    {"id": "A2", "question": "Nas √∫ltimas duas semanas, voc√™ se sentiu para baixo, deprimido ou sem esperan√ßas?", "options": ["Sim", "N√£o", "Prefiro n√£o responder"]},
    {"id": "A3", "question": "Voc√™ perdeu o interesse ou o prazer em fazer coisas que normalmente gosta?", "options": ["Sim", "N√£o", "Prefiro n√£o responder"]},
    {"id": "A4", "question": "Nas √∫ltimas duas semanas, voc√™ se sentiu nervoso, ansioso ou tenso?", "options": ["Sim", "N√£o", "Prefiro n√£o responder"]},
    {"id": "A5", "question": "Voc√™ teve dificuldade em parar ou controlar as preocupa√ß√µes?", "options": ["Sim", "N√£o", "Prefiro n√£o responder"]},
    {"id": "A6", "question": "Voc√™ tem se sentido t√£o agitado que √© dif√≠cil ficar parado ou relaxar?", "options": ["Sim", "N√£o", "Prefiro n√£o responder"]},
]

# NOVAS PERGUNTAS DE ORIGEM - Apenas 2 perguntas
ORIGIN_QUESTIONS = [
    {
        "id": "O1", 
        "question": "Sabemos que coisas do trabalho e da vida pessoal podem se misturar. Para agir melhor, de onde vem essa situa√ß√£o?",
        "type": "multiple choice",
        "options": ["Do ambiente de trabalho", "Da vida pessoal", "Dos dois", "Prefiro n√£o responder"]
    },
    {
        "id": "O2", 
        "question": "√â importante saber se a empresa tem condi√ß√µes de agir sobre o que voc√™ trouxe. Na sua opini√£o, a empresa poderia fazer algo para melhorar essa situa√ß√£o?",
        "type": "text"
    }
]

# MAPEAMENTO DE DIMENS√ïES PARA DESCRI√á√ïES DETALHADAS
DIMENSION_DESCRIPTIONS = {
    "Qualidade do sono e disposi√ß√£o": "na qualidade do sono e disposi√ß√£o e ind√≠cios de fadiga/ins√¥nia",
    "√Çnimo e motiva√ß√£o": "no √¢nimo e motiva√ß√£o e ind√≠cios de falta de √¢nimo positivo e satisfa√ß√£o no trabalho",
    "Estresse e ansiedade": "em lidar com demandas sem estresse e manter rendimento",
    "Equil√≠brio vida-trabalho": "no equil√≠brio trabalho e descanso",
    "Exig√™ncias de tempo no trabalho": "nas exig√™ncias de tempo no trabalho, ind√≠cios de press√£o cont√≠nua e falta de tempo suficiente para a vida pessoal"
}

# =========================
# Database
# =========================
def init_db_pool():
    global db_pool
    if db_pool is None:
        try:
            db_pool = pool.ThreadedConnectionPool(
                1, 5,
                host=DB_CONFIG["host"],
                port=DB_CONFIG["port"],
                dbname=DB_CONFIG["dbname"],
                user=DB_CONFIG["user"],
                password=DB_CONFIG["password"],
                connect_timeout=15
            )
            print(f"[DB Pool] Created successfully")
        except Exception as e:
            print(f"[DB Pool Error] {e}")
            raise

init_db_pool()

def close_db_pool():
    global db_pool
    if db_pool:
        db_pool.closeall()

atexit.register(close_db_pool)

@contextmanager
def get_db_connection():
    global db_pool
    conn = None
    try:
        if db_pool is None:
            init_db_pool()
        conn = db_pool.getconn()
        if conn:
            yield conn
            conn.commit()
    except Exception as e:
        if conn:
            conn.rollback()
        print(f"[DB Error] {e}")
        raise
    finally:
        if conn and db_pool:
            db_pool.putconn(conn)

# =========================
# Gest√£o de Crise com LLM
# =========================
class CrisisManager:
    """Gerencia conversas durante crises de sa√∫de mental"""
    
    def __init__(self, sender_id: str, load_existing: bool = True):
        self.sender_id = sender_id
        self.crisis_history = []
        self.crisis_type = None
        self.safety_score = 0
        self.interaction_count = 0
        # S√≥ carrega estado existente se solicitado
        if load_existing:
            self.load_crisis_state()
    
    def load_crisis_state(self):
        """Carrega estado da crise do banco de dados"""
        try:
            with get_db_connection() as conn:
                with conn.cursor() as cur:
                    cur.execute("""
                        SELECT crisis_history, crisis_type, safety_score, interaction_count
                        FROM crisis_state
                        WHERE sender_id = %s AND active = true
                        ORDER BY created_at DESC LIMIT 1
                    """, (self.sender_id,))
                    
                    result = cur.fetchone()
                    if result:
                        self.crisis_history = json.loads(result[0]) if result[0] else []
                        self.crisis_type = result[1]
                        self.safety_score = result[2] or 0
                        self.interaction_count = result[3] or 0
                        print(f"[Crisis State] Estado existente carregado: tipo={self.crisis_type}, intera√ß√µes={self.interaction_count}, hist√≥rico={len(self.crisis_history)} mensagens")
                        
                        # Verifica se crisis_type √© v√°lido
                        if not self.crisis_type:
                            print(f"[Crisis State] AVISO: crisis_type est√° None/vazio no banco de dados! Definindo como 'unknown'")
                            self.crisis_type = 'unknown'  # Define um padr√£o
                            # Atualiza no banco com o tipo corrigido
                            cur.execute("""
                                UPDATE crisis_state 
                                SET crisis_type = %s, updated_at = %s
                                WHERE sender_id = %s AND active = true
                            """, ('unknown', datetime.utcnow(), self.sender_id))
                    else:
                        # N√£o √© erro - apenas n√£o h√° estado anterior (primeira crise ou ap√≥s reset)
                        print(f"[Crisis State] Novo estado de crise ser√° criado para {self.sender_id}")
        except Exception as e:
            print(f"[Crisis State Load Error] {e}")
            # Em caso de erro, mant√©m valores padr√£o j√° inicializados
    
    def save_crisis_state(self):
        """Salva estado da crise no banco de dados"""
        try:
            with get_db_connection() as conn:
                with conn.cursor() as cur:
                    cur.execute("""
                        INSERT INTO crisis_state 
                        (sender_id, crisis_history, crisis_type, safety_score, 
                         interaction_count, active, updated_at)
                        VALUES (%s, %s, %s, %s, %s, %s, %s)
                        ON CONFLICT (sender_id, active) 
                        WHERE active = true
                        DO UPDATE SET
                            crisis_history = EXCLUDED.crisis_history,
                            crisis_type = EXCLUDED.crisis_type,
                            safety_score = EXCLUDED.safety_score,
                            interaction_count = EXCLUDED.interaction_count,
                            updated_at = EXCLUDED.updated_at
                    """, (
                        self.sender_id,
                        json.dumps(self.crisis_history, ensure_ascii=False),
                        self.crisis_type,
                        self.safety_score,
                        self.interaction_count,
                        True,
                        datetime.utcnow()
                    ))
        except Exception as e:
            print(f"[Crisis State Save Error] {e}")
    
    def end_crisis(self, reason: str):
        """Finaliza a crise e marca como inativa"""
        with get_db_connection() as conn:
            with conn.cursor() as cur:
                cur.execute("""
                    UPDATE crisis_state 
                    SET active = false, 
                        resolution_reason = %s,
                        resolved_at = %s
                    WHERE sender_id = %s AND active = true
                """, (reason, datetime.utcnow(), self.sender_id))
    
    def get_crisis_prompt(self) -> str:
        """Gera prompt espec√≠fico para o tipo de crise"""
        base_prompt = f"""Voc√™ √© um assistente de sa√∫de mental treinado, conduzindo uma conversa de suporte durante uma crise.

CONTEXTO DA CRISE:
- Tipo de risco detectado: {self.crisis_type}
- N√∫mero de intera√ß√µes at√© agora: {self.interaction_count}
- Score de seguran√ßa atual (0-10, onde 10 √© seguro): {self.safety_score}

HIST√ìRICO RECENTE DA CONVERSA:
{self._format_history()}

PROTOCOLO PARA {(self.crisis_type or 'UNKNOWN').upper()}:
{self._get_protocol_for_type()}

SUAS RESPONSABILIDADES:
1. A conversa deve ser emp√°tica e n√£o-julgamental
2. Avaliar continuamente o estado emocional do usu√°rio
3. Oferecer recursos de emerg√™ncia quando apropriado (sem ser repetitivo)
4. Conduzir a conversa at√© que o usu√°rio esteja estabilizado
5. NUNCA minimizar os sentimentos do usu√°rio
6. SEMPRE validar as emo√ß√µes antes de oferecer solu√ß√µes

INSTRU√á√ÉO ESPECIAL - RETOMADA DO QUESTION√ÅRIO:
- Se o usu√°rio expressar QUALQUER uma dessas situa√ß√µes:
  * "estou melhor" / "j√° estou melhor" / "me sinto melhor"
  * "quero continuar" / "desejo continuar" / "continuar o question√°rio"
  * "voltar ao question√°rio" / "retomar o question√°rio"
  * "j√° passou" / "t√° tudo bem" / "estou bem"
- E voc√™ avaliar que ele est√° minimamente est√°vel (n√£o precisa estar 100% perfeito)
- VOC√ä DEVE OBRIGATORIAMENTE:
  1. Escrever uma mensagem de acolhimento e confirma√ß√£o
  2. TERMINAR sua resposta EXATAMENTE com: [RETOMAR_QUESTIONARIO]
  
EXEMPLO OBRIGAT√ìRIO de resposta quando usu√°rio quer continuar:
"Que bom que voc√™ est√° se sentindo melhor! Fico feliz em saber que quer continuar. Vamos retomar o question√°rio de onde paramos. [RETOMAR_QUESTIONARIO]"

CRIT√âRIOS FLEX√çVEIS PARA RETOMADA:
- Usu√°rio expressou melhora OU desejo de continuar (n√£o precisa ser os dois)
- N√£o h√° sinais de risco IMINENTE (pode haver algum desconforto residual)
- Usu√°rio parece capaz de responder perguntas simples
- Se o usu√°rio INSISTE em continuar, PERMITA (mesmo que voc√™ tenha d√∫vidas)

IMPORTANTE:
- Use a frase [RETOMAR_QUESTIONARIO] apenas quando tiver ABSOLUTA certeza de que √© seguro
- Se tiver qualquer d√∫vida, continue a conversa de apoio
- N√∫mero atual de mensagens na conversa: {self.interaction_count}
- Mantenha um tom caloroso, humano e acolhedor
- Use linguagem simples e acess√≠vel
- Responda em portugu√™s brasileiro

Responda √† √∫ltima mensagem do usu√°rio de forma emp√°tica e helpful."""

        return base_prompt
    
    def _format_history(self) -> str:
        """Formata hist√≥rico para o prompt"""
        if not self.crisis_history:
            return "In√≠cio da conversa de suporte"
        
        formatted = []
        for entry in self.crisis_history[-5:]:  # √öltimas 5 mensagens
            role = "Usu√°rio" if entry['role'] == 'user' else "Assistente"
            formatted.append(f"{role}: {entry['content']}")
        
        return "\n".join(formatted)
    
    def _get_protocol_for_type(self) -> str:
        """Retorna protocolo espec√≠fico por tipo de crise"""
        protocols = {
            'suicide': """
‚ö†Ô∏è Sinto muito pelo que voc√™ est√° vivendo. Sua vida √© valiosa.
üëâ Se voc√™ est√° em perigo imediato, ligue 190.
üëâ Voc√™ tamb√©m pode ligar agora para o 188 (CVV ‚Äì Centro de Valoriza√ß√£o da Vida). √â gratuito, sigiloso e funciona 24h.
üëâ Se puder, procure tamb√©m o RH ou o canal de apoio da sua empresa, que pode indicar ajuda pr√≥xima.
üëâ Se quiser, voc√™ pode compartilhar como acredita que a empresa pode ajudar nessa situa√ß√£o. Podemos fazer sua voz ser registrada de forma segura.
A Vocal Silence n√£o substitui servi√ßos m√©dicos ou de emerg√™ncia. Procure ajuda especializada sempre que precisar.
""",
            'violence': """
‚ö†Ô∏è Entendemos a seriedade do que voc√™ compartilhou.
Se voc√™ est√° em risco ou pensa em machucar algu√©m, √© muito importante buscar ajuda imediata.
üëâ Em situa√ß√µes de sofrimento intenso, voc√™ tamb√©m pode ligar para o 188 (CVV ‚Äì Centro de Valoriza√ß√£o da Vida), dispon√≠vel 24 horas por dia, gratuitamente.
üëâ Al√©m disso, voc√™ pode procurar o RH ou o canal de apoio da sua empresa, que poder√° orientar sobre medidas de prote√ß√£o e acolhimento.
üëâ Se quiser, voc√™ pode compartilhar como acredita que a empresa pode ajudar nessa situa√ß√£o. Podemos fazer sua voz ser registrada de forma segura.
A Vocal Silence n√£o substitui servi√ßos m√©dicos ou de emerg√™ncia. Procure ajuda especializada sempre que precisar.
""",
            'substance': """
‚ö†Ô∏è Obrigado por compartilhar algo t√£o sens√≠vel.
Sabemos que o uso de subst√¢ncias pode ser dif√≠cil de lidar e n√£o estamos aqui para julgar, mas para ouvir.
üëâ Se quiser, voc√™ pode compartilhar como acredita que a empresa pode ajudar nessa situa√ß√£o. Podemos fazer sua voz ser registrada de forma segura.
üëâ Se voc√™ sente que precisa de apoio, pode procurar servi√ßos especializados como o CAPS AD (Centro de Aten√ß√£o Psicossocial √Ålcool e Drogas) na sua regi√£o, ou grupos de apoio como AA (Alco√≥licos An√¥nimos) e NA (Narc√≥ticos An√¥nimos).
üëâ O processo de mudan√ßa √© desafiador, e reca√≠das fazem parte da recupera√ß√£o ‚Äì n√£o significam fracasso.
A Vocal Silence n√£o substitui acompanhamento m√©dico ou terap√™utico. Procure ajuda especializada sempre que precisar.
""",
            'psychosis': """
‚ö†Ô∏è Obrigado por compartilhar sua experi√™ncia.
Percebemos que voc√™ pode estar passando por um momento delicado e √© muito importante procurar ajuda profissional o quanto antes.
üëâ Se houver risco imediato para voc√™ ou para outras pessoas, ligue 190.
üëâ Tamb√©m √© fundamental buscar atendimento m√©dico ou em um CAPS (Centro de Aten√ß√£o Psicossocial) na sua regi√£o, que conta com equipes preparadas para acolher situa√ß√µes como essa.
üëâ Se sentir confort√°vel, voc√™ pode compartilhar como a empresa pode apoiar nesse contexto. Podemos registrar sua voz de forma segura.
A Vocal Silence n√£o substitui acompanhamento m√©dico ou terap√™utico, mas refor√ßamos a import√¢ncia de procurar ajuda especializada.
""",
            'help_request': """
‚ö†Ô∏è Percebo que voc√™ est√° passando por um momento dif√≠cil e precisa de ajuda.
üëâ Voc√™ pode ligar para o 188 (CVV ‚Äì Centro de Valoriza√ß√£o da Vida). √â gratuito, sigiloso e funciona 24h.
üëâ Em emerg√™ncias, ligue 190 ou 192 (SAMU).
üëâ Se puder, procure tamb√©m o RH ou o canal de apoio da sua empresa.
üëâ Como voc√™ est√° se sentindo agora? Estou aqui para ouvir e apoiar voc√™.
A Vocal Silence n√£o substitui servi√ßos m√©dicos ou de emerg√™ncia, mas estamos aqui para acolher voc√™ neste momento.
"""
        }
        
        return protocols.get(self.crisis_type or 'help_request', protocols.get('help_request', protocols['suicide']))
    
    def evaluate_safety(self, user_message: str, assistant_response: str) -> Dict[str, Any]:
        """Avalia o n√≠vel de seguran√ßa ap√≥s cada intera√ß√£o"""
        try:
            # Verifica se usu√°rio expressou melhora explicitamente
            improvement_phrases = [
                'estou melhor', 't√¥ melhor', 'to melhor', 'me sinto melhor',
                'j√° passou', 'passou j√°', 't√° tudo bem', 'ta tudo bem',
                'estou bem', 'to bem', 't√¥ bem', 'me sinto bem',
                'quero continuar', 'continuar o question√°rio', 
                'voltar ao question√°rio', 'seguir com o question√°rio'
            ]
            
            # Frases que indicam melhora real no estado emocional
            emotional_improvement_phrases = [
                'estou melhor', 'me sinto melhor', 't√¥ melhor', 'to melhor',
                'estou bem', 'me sinto bem', 't√¥ bem', 'to bem',
                'j√° passou', 'passou j√°', 't√° tudo bem', 'ta tudo bem',
                'me acalmei', 't√¥ mais calmo', 'to mais calma'
            ]
            
            user_msg_lower = user_message.lower()
            explicit_improvement = any(phrase in user_msg_lower for phrase in improvement_phrases)
            emotional_improvement = any(phrase in user_msg_lower for phrase in emotional_improvement_phrases)
            
            eval_prompt = f"""Avalie a seguran√ßa desta conversa de crise.

Tipo de crise: {self.crisis_type}
Mensagem do usu√°rio: "{user_message}"
Resposta do assistente: "{assistant_response}"
Score de seguran√ßa anterior: {self.safety_score}/10
Usu√°rio expressou melhora explicitamente: {explicit_improvement}
Usu√°rio expressou melhora emocional real: {emotional_improvement}

Analise e responda APENAS em JSON:
{{
  "safety_score": 0-10 (10 = totalmente seguro),
  "risk_level": "critical" | "high" | "medium" | "low",
  "can_resume_questionnaire": true/false,
  "reasoning": "breve explica√ß√£o",
  "user_expressed_improvement": true/false,
  "emotional_improvement_detected": true/false,
  "specific_improvements": ["lista de melhorias observadas"]
}}

Considere:
- O usu√°rio expressou estar melhor? (detectado: {explicit_improvement})
- H√° melhora emocional real? (detectado: {emotional_improvement})
- H√° sinais de estabiliza√ß√£o emocional?
- Os riscos diminu√≠ram?
- √â seguro retomar atividades normais?

CRIT√âRIOS FLEX√çVEIS:
- Se usu√°rio disse estar melhor/bem E score anterior >= 3: pode retomar
- Se h√° melhora emocional clara E score anterior >= 4: pode retomar  
- Se usu√°rio insiste em continuar E mostra estabilidade: pode retomar ap√≥s confirma√ß√£o"""

            response = client.chat.completions.create(
                model=MODEL_NAME,
                messages=[{"role": "system", "content": eval_prompt}],
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content)
            return result
            
        except Exception as e:
            print(f"[Safety Evaluation Error] {e}")
            return {
                "safety_score": self.safety_score,
                "risk_level": "high",
                "can_resume_questionnaire": False,
                "reasoning": "Erro na avalia√ß√£o",
                "user_expressed_improvement": False,
                "specific_improvements": []
            }
    
    def handle_crisis_conversation(self, user_message: str) -> Tuple[str, bool, Dict[str, Any]]:
        """
        Gerencia conversa durante crise - LLM conduz completamente a conversa
        Retorna: (resposta, pode_retomar_questionario, metadata)
        """
        self.interaction_count += 1
        
        # Adiciona mensagem ao hist√≥rico
        self.crisis_history.append({
            "role": "user",
            "content": user_message,
            "timestamp": datetime.utcnow().isoformat()
        })
        
        # Gera resposta com LLM
        try:
            prompt = self.get_crisis_prompt()
            messages = [
                {"role": "system", "content": prompt},
                {"role": "user", "content": user_message}
            ]
            
            response = client.chat.completions.create(
                model=MODEL_NAME,
                messages=messages,
                max_completion_tokens=600
            )
            
            assistant_response = response.choices[0].message.content
            print(f"[Crisis Manager] Resposta do LLM (primeiros 200 caracteres): {assistant_response[:200]}")
            
            # Adiciona resposta ao hist√≥rico
            self.crisis_history.append({
                "role": "assistant",
                "content": assistant_response,
                "timestamp": datetime.utcnow().isoformat()
            })
            
            # Verifica se a LLM sinalizou para retomar o question√°rio (m√∫ltiplas varia√ß√µes)
            resume_signals = [
                "[RETOMAR_QUESTIONARIO]",
                "[RETOMAR QUESTIONARIO]", 
                "[RETOMAR_QUESTION√ÅRIO]",
                "[RETOMAR QUESTION√ÅRIO]"
            ]
            
            can_resume = False
            for signal in resume_signals:
                if signal in assistant_response:
                    can_resume = True
                    # Remove o sinal da resposta mas garante que h√° conte√∫do
                    assistant_response = assistant_response.replace(signal, "").strip()
                    print(f"[Crisis Manager] Sinal de retomada detectado: {signal}")
                    print(f"[Crisis Manager] Resposta ap√≥s remover sinal: '{assistant_response}'")
                    
                    # Se a resposta ficou vazia ap√≥s remover o sinal, adiciona mensagem padr√£o
                    if not assistant_response:
                        assistant_response = "Que bom que voc√™ est√° se sentindo melhor! Vamos retomar o question√°rio de onde paramos."
                        print(f"[Crisis Manager] Resposta estava vazia, usando mensagem padr√£o")
                    break
            
            if can_resume:
                # Finaliza a crise
                self.end_crisis(f"LLM avaliou que usu√°rio est√° pronto para retomar. Intera√ß√µes: {self.interaction_count}")
                print(f"[Crisis Manager] LLM sinalizou retomada ap√≥s {self.interaction_count} intera√ß√µes")
            
            # Mecanismo de seguran√ßa: se muitas intera√ß√µes sem retomada, oferece op√ß√£o
            elif self.interaction_count >= 10:
                assistant_response += f"\n\nüí° Nota: J√° conversamos bastante ({self.interaction_count} mensagens). Se voc√™ se sente melhor e quer continuar o question√°rio, me avise diretamente."
            
            # Atualiza score de seguran√ßa baseado na progress√£o da conversa
            if can_resume:
                self.safety_score = 8  # Score alto se LLM aprovou retomada
            else:
                # Incrementa gradualmente o score conforme a conversa progride
                self.safety_score = min(self.safety_score + 0.5, 6)
            
            # Salva estado
            self.save_crisis_state()
            
            # Adiciona recursos de emerg√™ncia periodicamente (a cada 4 mensagens)
            if self.interaction_count % 4 == 0 and not can_resume:
                assistant_response += "\n\nüìû Lembre-se: CVV 188 (24h) | SAMU 192"
            
            metadata = {
                "crisis_type": self.crisis_type,
                "interaction_count": self.interaction_count,
                "safety_score": self.safety_score,
                "can_resume": can_resume,
                "llm_managed": True,
                "resume_signal_detected": can_resume
            }
            
            return assistant_response, can_resume, metadata
            
        except Exception as e:
            print(f"[Crisis Conversation Error] {e}")
            return (
                "Estou aqui para te apoiar. Como voc√™ est√° se sentindo agora? "
                "Lembre-se que h√° ajuda dispon√≠vel: CVV 188 (24h) | SAMU 192",
                False,
                {"error": str(e)}
            )

# =========================
# Protocolo de Seguran√ßa Aprimorado
# =========================
class SafetyProtocol:
    EMERGENCY_KEYWORDS = {
        'suicide': ['suic√≠dio', 'suicidio', 'me matar', 'tirar minha vida', 'n√£o aguento mais', 
                   'nao aguento mais', 'acabar com tudo', 'desistir de viver', 'me cortar', 
                   'me machucar', 'automutila√ß√£o', 'automutilacao'],
        'violence': ['matar algu√©m', 'matar alguem', 'machucar', 'viol√™ncia', 'violencia', 
                     'agredir', 'ferir', 'atacar', 'vingan√ßa', 'vinganca'],
        'substance': ['overdose', 'drogas', '√°lcool', 'alcool', 'v√≠cio', 'vicio', 
                     'depend√™ncia', 'dependencia', 'abuso de subst√¢ncia'],
        'psychosis': ['vozes', 'alucina√ß√£o', 'alucinacao', 'persegui√ß√£o', 'perseguicao',
                     'compl√¥', 'complo', 'del√≠rio', 'delirio', 'paranoia'],
        'help_request': ['me sentindo mal', 'sentindo mal', 'preciso de ajuda', 'preciso ajuda',
                        'contato de algu√©m', 'contato de alguem', 'contato para ajudar',
                        'algu√©m para me ajudar', 'alguem para me ajudar']
    }
    
    @staticmethod
    def normalize_text(text: str) -> str:
        """Normaliza texto removendo acentos e convertendo para min√∫sculo"""
        nfkd = unicodedata.normalize('NFKD', text.lower())
        return ''.join([c for c in nfkd if not unicodedata.combining(c)])
    
    @classmethod
    def quick_check(cls, message: str) -> Dict[str, Any]:
        """Verifica√ß√£o r√°pida por palavras-chave (usado como fallback)"""
        normalized_msg = cls.normalize_text(message)
        
        for emergency_type, keywords in cls.EMERGENCY_KEYWORDS.items():
            for keyword in keywords:
                if cls.normalize_text(keyword) in normalized_msg:
                    return {'detected': True, 'type': emergency_type, 'keyword': keyword}
        
        return {'detected': False}
    
    @classmethod
    def llm_screening(cls, message: str) -> Dict[str, Any]:
        """Triagem inicial com modelo leve - SEMPRE executada"""
        try:
            prompt = f"""Analise esta mensagem e identifique poss√≠veis riscos de seguran√ßa em sa√∫de mental.

Mensagem: "{message}"

Categorias de risco:
1. suicide: men√ß√µes a suic√≠dio, automutila√ß√£o, desistir de viver
2. violence: amea√ßas de viol√™ncia contra outros, homic√≠dio
3. substance: abuso de subst√¢ncias, overdose, depend√™ncia qu√≠mica
4. psychosis: sinais de psicose, alucina√ß√µes, del√≠rios, paranoia
5. help_request: pedidos de ajuda, contatos de emerg√™ncia, men√ß√µes a se sentir mal e precisar de apoio
6. none: nenhum risco detectado

IMPORTANTE: 
- "Estou me sentindo mal" + pedido de ajuda/contato = help_request
- "Preciso de ajuda" ou "tem contato de algu√©m" = help_request
- Qualquer pedido de contato ou ajuda profissional = help_request

Responda EXATAMENTE neste formato JSON:
{{
  "has_risk": true/false,
  "type": "suicide" ou "violence" ou "substance" ou "psychosis" ou "help_request" ou "none",
  "confidence": 0.0 a 1.0,
  "reasoning": "breve explica√ß√£o em portugu√™s"
}}

Seja conservador - na d√∫vida, marque como risco."""

            response = client.chat.completions.create(
                model=SCREENING_MODEL,
                messages=[{"role": "system", "content": prompt}],
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content)
            return {
                "has_risk": result.get("has_risk", False),
                "type": result.get("type", "none"),
                "confidence": result.get("confidence", 0),
                "reasoning": result.get("reasoning", ""),
                "screening_model": SCREENING_MODEL
            }
            
        except Exception as e:
            print(f"[Safety Screening Error] {e}")
            # Fallback para quick_check
            print("[Safety] Usando quick_check como fallback")
            quick_result = cls.quick_check(message)
            if quick_result['detected']:
                return {
                    "has_risk": True,
                    "type": quick_result['type'],
                    "confidence": 0.8,
                    "reasoning": f"Detectado por palavra-chave: {quick_result['keyword']}",
                    "screening_model": "quick_check"
                }
            return {
                "has_risk": False,
                "type": "none",
                "confidence": 0,
                "reasoning": "Sem riscos detectados",
                "screening_model": "quick_check"
            }
    
    @classmethod
    def llm_detailed_check(cls, message: str, initial_assessment: Dict[str, Any]) -> Dict[str, Any]:
        """Verifica√ß√£o detalhada com modelo avan√ßado quando risco √© detectado"""
        try:
            risk_type = initial_assessment.get('type', 'unknown')
            
            prompt = f"""Voc√™ √© um especialista em sa√∫de mental analisando uma mensagem de risco.

Mensagem do usu√°rio: "{message}"

Avalia√ß√£o inicial indicou poss√≠vel risco de: {risk_type}
Raz√£o: {initial_assessment.get('reasoning', 'N/A')}

Fa√ßa uma an√°lise DETALHADA e responda em JSON:
{{
  "is_emergency": true/false,
  "type": "{risk_type}" ou outro tipo se mais apropriado,
  "severity": "low" ou "medium" ou "high" ou "critical",
  "confidence": 0.0 a 1.0,
  "detailed_analysis": "an√°lise detalhada em portugu√™s",
  "recommended_action": "a√ß√£o recomendada",
  "initial_safety_score": 0-10 (10 = seguro),
  "requires_immediate_intervention": true/false
}}

Considere:
- Gravidade e imin√™ncia do risco
- Contexto e nuances da mensagem
- Necessidade de interven√ß√£o imediata
- Tom apropriado para a resposta"""

            response = client.chat.completions.create(
                model=MODEL_NAME,
                messages=[{"role": "system", "content": prompt}],
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content)
            result["detailed_check_model"] = MODEL_NAME
            return result
            
        except Exception as e:
            print(f"[Safety Detailed Check Error] {e}")
            # Em caso de erro, assume emerg√™ncia por precau√ß√£o
            return {
                "is_emergency": True,
                "type": initial_assessment.get('type', 'unknown'),
                "severity": "high",
                "confidence": 0.7,
                "detailed_analysis": "Erro na an√°lise detalhada - assumindo emerg√™ncia por precau√ß√£o",
                "recommended_action": "Iniciar protocolo de suporte",
                "initial_safety_score": 3,
                "requires_immediate_intervention": True,
                "detailed_check_model": "error"
            }

# =========================
# Parser de Respostas (mantido igual)
# =========================
class ResponseParser:
    
    @staticmethod
    def normalize(text: str) -> str:
        """Normaliza texto para compara√ß√£o"""
        nfkd = unicodedata.normalize('NFKD', text.lower().strip())
        return ''.join([c for c in nfkd if not unicodedata.combining(c)])
    
    @classmethod
    def parse_multiple_choice(cls, message: str, options: list) -> Dict[str, Any]:
        """Parse de m√∫ltipla escolha"""
        message = message.strip()
        
        # Mapeia emojis de n√∫meros para √≠ndices
        number_emoji_map = {
            '1Ô∏è‚É£': 0, '2Ô∏è‚É£': 1, '3Ô∏è‚É£': 2, '4Ô∏è‚É£': 3, '5Ô∏è‚É£': 4,
            '6Ô∏è‚É£': 5, '7Ô∏è‚É£': 6, '8Ô∏è‚É£': 7, '9Ô∏è‚É£': 8
        }
        
        # Tenta emoji de n√∫mero primeiro
        if message in number_emoji_map:
            idx = number_emoji_map[message]
            if idx < len(options):
                return {'success': True, 'value': options[idx]}
        
        # Tenta n√∫mero normal
        if message.isdigit():
            idx = int(message) - 1
            if 0 <= idx < len(options):
                return {'success': True, 'value': options[idx]}
        
        # Tenta match exato ou parcial
        normalized_msg = cls.normalize(message)
        for i, option in enumerate(options):
            if cls.normalize(option) == normalized_msg:
                return {'success': True, 'value': option}
            if cls.normalize(option) in normalized_msg or normalized_msg in cls.normalize(option):
                return {'success': True, 'value': option}
        
        return {'success': False}
    
    @classmethod
    def parse_likert(cls, message: str) -> Dict[str, Any]:
        """Parse de escala Likert"""
        message = message.strip()
        
        # Mapeia emojis e n√∫meros para valores
        emoji_map = {
            'üòû': 1, 'üôÅ': 2, 'üòê': 3, 'üôÇ': 4, 'üòÑ': 5,
            '1': 1, '2': 2, '3': 3, '4': 4, '5': 5,
            '1Ô∏è‚É£': 1, '2Ô∏è‚É£': 2, '3Ô∏è‚É£': 3, '4Ô∏è‚É£': 4, '5Ô∏è‚É£': 5
        }
        
        # Verifica n√∫mero direto
        if message in emoji_map:
            return {'success': True, 'value': emoji_map[message]}
        
        # Verifica palavras-chave
        normalized = cls.normalize(message)
        keywords = {
            1: ['discordo totalmente', 'discordo muito', 'pessimo', 'horrivel'],
            2: ['discordo', 'ruim', 'mal'],
            3: ['neutro', 'medio', 'mais ou menos', 'talvez'],
            4: ['concordo', 'bom', 'bem'],
            5: ['concordo totalmente', 'concordo muito', 'otimo', 'excelente']
        }
        
        for value, words in keywords.items():
            for word in words:
                if cls.normalize(word) in normalized:
                    return {'success': True, 'value': value}
        
        return {'success': False}
    
    @classmethod
    def parse_text(cls, message: str) -> Dict[str, Any]:
        """Parse de texto livre"""
        message = message.strip()
        if len(message) > 0:
            return {'success': True, 'value': message[:500]}  # Limita tamanho
        return {'success': False}
    
    @classmethod
    def llm_parse(cls, message: str, question: dict, attempt_context: dict = None) -> Dict[str, Any]:
        """
        Usa LLM para analisar mensagens amb√≠guas:
        - Identifica se √© pergunta sobre o question√°rio
        - Interpreta respostas amb√≠guas
        - Detecta tentativas de desvio
        - Detecta inten√ß√£o de pular pergunta
        """
        try:
            qtype = question.get('type', 'text')
            required = question.get('required', False)
            question_id = question.get('id', 0)
            attempt_context = attempt_context or {}
            clarification_count = attempt_context.get('clarification_count', 0)
            skipped_count = attempt_context.get('skipped_questions', 0)
            
            # Determina quais perguntas s√£o obrigat√≥rias baseado no JSON
            # IDs das perguntas obrigat√≥rias: 4 (unidade), 5 (√°rea/setor), 7 (tipo contrata√ß√£o)
            required_question_ids = [4, 5, 7]
            is_required = question_id in required_question_ids or required
            
            # Primeiro, analisa se √© pergunta ou resposta
            analysis_prompt = f"""Voc√™ est√° auxiliando no question√°rio psicossocial da Vocal Silence.

SOBRE A VOCAL SILENCE:
A Vocal Silence tem a miss√£o de tornar o cuidado com a sa√∫de mental um direito acess√≠vel, utilizando intelig√™ncia artificial para fortalecer a autonomia e o autoconhecimento individual e coletivo. 
"Vocal" representa o impulso de falar, de ser ouvido, de comunicar dores, emo√ß√µes e necessidades.
"Silence" √© a pausa necess√°ria, o espa√ßo de escuta, de reflex√£o, de reconex√£o com o que sentimos mas ainda n√£o sabemos nomear.
Cuidar da sa√∫de mental n√£o √© apenas permitir que as pessoas falem ‚Äî √© garantir que sejam compreendidas.
Para saber mais: https://www.vocalsilence.com/behind-the-listening

SOBRE O QUESTION√ÅRIO:
- Total de 41 perguntas para an√°lise psicossocial
- Objetivo: Melhorar a sa√∫de mental dos colaboradores da empresa
- Respostas s√£o an√¥nimas e confidenciais
- Pode haver perguntas adicionais se identificarmos algum risco
- Perguntas opcionais podem ser puladas (m√°ximo 5)
- Perguntas obrigat√≥rias: unidade de trabalho (ID 4), √°rea/setor (ID 5) e tipo de contrata√ß√£o (ID 7)

CONTEXTO DA PERGUNTA ATUAL:
Pergunta ID {question_id}: "{question.get('question', '')}"
Tipo: {qtype}
{f"Op√ß√µes: {question.get('options', [])}" if question.get('options') else ""}
Esta pergunta √©: {"OBRIGAT√ìRIA - n√£o pode ser pulada" if is_required else "OPCIONAL - pode ser pulada"}
Perguntas j√° puladas: {skipped_count}/5
Esclarecimentos j√° fornecidos nesta pergunta: {clarification_count}

Mensagem do usu√°rio: "{message}"

AN√ÅLISE:
Determine a inten√ß√£o do usu√°rio:
1. "question" - Fazendo pergunta sobre o question√°rio ou pedindo esclarecimento
2. "answer" - Tentando responder a pergunta atual
3. "skip_request" - Querendo pular/n√£o responder a pergunta
4. "off_topic" - Assunto n√£o relacionado ao question√°rio

REGRAS PARA DETECTAR INTEN√á√ÉO DE PULAR:
- Frases expl√≠citas: "pular", "pr√≥xima", "passar", "pulo", "skip" = skip_request
- Recusa em responder: "n√£o quero responder", "prefiro n√£o responder", "n√£o vou responder" = skip_request
- Incerteza genu√≠na: "n√£o sei", "n√£o tenho certeza", "n√£o fa√ßo ideia" = skip_request
- Marcadores vazios: "-", "...", "n/a", "NA", "n√£o aplic√°vel" = skip_request
- IMPORTANTE: "n√£o sei" sobre um TERMO (ex: "n√£o sei o que √© CLT") = question, n√£o skip_request
- Se a pergunta √© OBRIGAT√ìRIA, ainda detecte skip_request mas ser√° tratado diferente

REGRAS PARA PERGUNTAS/ESCLARECIMENTOS:
- Perguntas sobre termos: "o que √© CLT/PJ/turno/ass√©dio?" = question
- Perguntas sobre o processo: "quantas perguntas faltam?", "posso pular?" = question
- Perguntas sobre o question√°rio: "quem est√° conduzindo?", "quem aplica?", "quem faz o question√°rio?" = question
- Pedidos de esclarecimento: "n√£o entendi", "como assim?", "pode explicar?" = question
- Use tom emp√°tico e acolhedor nas respostas de esclarecimento

REGRAS ESPECIAIS PARA PERGUNTAS SOBRE O PROCESSO:
- "Quem est√° conduzindo o question√°rio?" = question (resposta: Vocal Silence com IA)
- "Quem aplica este question√°rio?" = question
- "Quem est√° fazendo as perguntas?" = question
- NUNCA interprete essas perguntas como respostas!

EXEMPLOS DE CLASSIFICA√á√ÉO:
- "pular" = skip_request
- "n√£o quero responder isso" = skip_request
- "n√£o sei" (sem contexto adicional) = skip_request
- "n√£o sei o que √© PJ" = question (pergunta sobre termo)
- "posso pular esta pergunta?" = question (com inten√ß√£o secund√°ria de pular)
- "Quem est√° conduzindo o question√°rio?" = question (NUNCA answer)
- "CLT" = answer
- "acho que √© CLT" = answer
- "qual o clima hoje?" = off_topic

Responda APENAS em JSON:
{{
  "intent": "question" | "answer" | "skip_request" | "off_topic",
  "confidence": 0.0-1.0,
  "wants_to_skip": true/false,
  "clarification_response": "resposta emp√°tica e clara se for pergunta v√°lida (m√°ximo 3 linhas)",
  "interpreted_value": "valor interpretado se for resposta",
  "should_insist": true/false (true se j√° forneceu 2+ esclarecimentos),
  "reasoning": "explica√ß√£o breve da decis√£o"
}}"""

            response = client.chat.completions.create(
                model=MODEL_NAME,
                messages=[{"role": "system", "content": analysis_prompt}],
                response_format={"type": "json_object"}
            )
            
            analysis = json.loads(response.choices[0].message.content)
            
            # Log para debug
            print(f"[LLM Parse] Intent: {analysis.get('intent')}, Confidence: {analysis.get('confidence')}, Message: {message[:50]}")
            
            # Se detectou inten√ß√£o de pular
            if analysis.get('intent') == 'skip_request' or analysis.get('wants_to_skip'):
                return {
                    'success': False,
                    'wants_to_skip': True,
                    'confidence': analysis.get('confidence', 0.8),
                    'llm_used': True,
                    'reasoning': analysis.get('reasoning', 'Usu√°rio quer pular a pergunta')
                }
            
            # Se for pergunta v√°lida sobre o question√°rio
            if analysis.get('intent') == 'question' and analysis.get('confidence', 0) > 0.6:
                # Se j√° deu muitos esclarecimentos, insiste na resposta
                if analysis.get('should_insist') or clarification_count >= 2:
                    return {
                        'success': False,
                        'is_clarification': True,
                        'clarification_limit_reached': True,
                        'message': "J√° forneci esclarecimentos sobre esta pergunta. Por favor, escolha uma das op√ß√µes apresentadas.",
                        'llm_used': True
                    }
                
                return {
                    'success': False,
                    'is_clarification': True,
                    'clarification_response': analysis.get('clarification_response', 'Vou esclarecer sua d√∫vida.'),
                    'llm_used': True
                }
            
            # Se for off-topic
            if analysis.get('intent') == 'off_topic' and analysis.get('confidence', 0) > 0.7:
                return {
                    'success': False,
                    'is_off_topic': True,
                    'message': "Por favor, vamos focar no question√°rio de sa√∫de ocupacional. Responda a pergunta apresentada.",
                    'llm_used': True
                }
            
            # Se chegou aqui, tenta interpretar como resposta
            if qtype == 'likert':
                interpret_prompt = f"""O usu√°rio respondeu: "{message}"
Para uma pergunta Likert (escala 1-5) sobre: "{question.get('question', '')}"

Interprete a resposta considerando:
1 = Discordo totalmente
2 = Discordo  
3 = Neutro
4 = Concordo
5 = Concordo totalmente

Exemplos de interpreta√ß√£o:
- "mais ou menos" = 3
- "sim" ou "concordo" = 4
- "com certeza" ou "totalmente" = 5
- "n√£o" ou "discordo" = 2
- "de jeito nenhum" = 1

Responda APENAS em formato JSON.

Se poss√≠vel interpretar com alta confian√ßa, retorne em formato JSON:
{{"value": 1-5, "confidence": 0.0-1.0}}
Se n√£o for poss√≠vel interpretar claramente, retorne em JSON:
{{"value": null, "confidence": 0}}"""
            
            elif qtype == 'multiple choice':
                options = question.get('options', [])
                interpret_prompt = f"""O usu√°rio respondeu: "{message}"
Para a pergunta: "{question.get('question', '')}"
Op√ß√µes dispon√≠veis: {options}

Tente identificar qual op√ß√£o o usu√°rio escolheu.
Considere abrevia√ß√µes, sin√¥nimos e respostas parciais.

Exemplos:
- Se op√ß√µes s√£o ["CLT", "PJ", "Estagi√°rio"] e usu√°rio disse "sou CLT", interprete como "CLT"
- Se usu√°rio disse apenas parte da op√ß√£o, mas √© identific√°vel, aceite

Se poss√≠vel interpretar com alta confian√ßa, retorne em formato JSON:
{{"value": "op√ß√£o exata da lista", "confidence": 0.0-1.0}}
Se n√£o for poss√≠vel interpretar claramente, retorne em JSON:
{{"value": null, "confidence": 0}}"""
            
            else:  # text
                # Para texto livre, aceita qualquer resposta n√£o vazia
                if len(message.strip()) > 0:
                    return {'success': True, 'value': message[:500], 'llm_used': True}
                return {'success': False, 'llm_used': True}
            
            interpretation = client.chat.completions.create(
                model=MODEL_NAME,
                messages=[{"role": "system", "content": interpret_prompt}],
                response_format={"type": "json_object"}
            )
            
            result = json.loads(interpretation.choices[0].message.content)
            
            if result.get('value') and result.get('confidence', 0) > 0.7:
                return {
                    'success': True,
                    'value': result['value'],
                    'llm_used': True,
                    'interpretation_confidence': result.get('confidence')
                }
            
            # Se n√£o conseguiu interpretar
            return {
                'success': False,
                'llm_used': True,
                'could_not_interpret': True,
                'message': "N√£o consegui entender sua resposta. Por favor, escolha uma das op√ß√µes apresentadas."
            }
            
        except Exception as e:
            print(f"[LLM Parse Error] {e}")
            return {'success': False, 'llm_used': True, 'error': str(e)}

# =========================
# State Machine (modificado para gerenciar crise com LLM)
# =========================
class QuestionnaireStateMachine:
    
    def __init__(self, sender_id: str):
        self.sender_id = sender_id
        self.state = None
        self.current_question_index = 0
        self.phase1_data = []
        self.followup_data = {"aprofundamento": [], "origem_riscos": {}}
        self.trigger_dimensions = []
        self.attempt_counts = {}
        self.skipped_questions = 0
        self.crisis_manager = None  # Gerenciador de crise
        self.pre_crisis_state = None  # Estado antes da crise
        self.pre_crisis_question_index = None  # √çndice da pergunta antes da crise
        self.load_questionnaire()
        self.load_state()
    
    def load_questionnaire(self):
        """Carrega question√°rio do arquivo JSON"""
        global _questionnaire_cache
        if _questionnaire_cache is None:
            with open("questionario.json", "r", encoding="utf-8") as f:
                _questionnaire_cache = json.load(f)
        self.questionnaire = _questionnaire_cache.get("questionnaire", [])
    
    def load_state(self):
        """Carrega estado do banco de dados"""
        with get_db_connection() as conn:
            with conn.cursor() as cur:
                cur.execute("""
                    SELECT current_state, current_question_index, phase1_data, 
                           followup_data, trigger_dimensions, attempt_counts, skipped_questions,
                           pre_crisis_state, pre_crisis_question_index
                    FROM questionnaire_state
                    WHERE sender_id = %s
                """, (self.sender_id,))
                
                result = cur.fetchone()
                if result:
                    self.state = State(result[0])
                    self.current_question_index = result[1]
                    self.phase1_data = json.loads(result[2]) if result[2] else []
                    self.followup_data = json.loads(result[3]) if result[3] else {"aprofundamento": [], "origem_riscos": {}}
                    self.trigger_dimensions = json.loads(result[4]) if result[4] else []
                    self.attempt_counts = json.loads(result[5]) if result[5] else {}
                    self.skipped_questions = result[6] or 0
                    self.pre_crisis_state = State(result[7]) if result[7] else None
                    self.pre_crisis_question_index = result[8]
                    
                    # Se estava em emerg√™ncia, carrega o gerenciador de crise
                    if self.state == State.EMERGENCY:
                        # Carrega gerenciador com estado existente
                        self.crisis_manager = CrisisManager(self.sender_id, load_existing=True)
                        # Garante que tem um tipo de crise v√°lido
                        if not self.crisis_manager.crisis_type:
                            self.crisis_manager.crisis_type = 'unknown'
                            print(f"[State Machine] AVISO: crisis_type estava vazio, definindo como 'unknown'")
                        print(f"[State Machine] Carregado gerenciador de crise: tipo={self.crisis_manager.crisis_type}")
                else:
                    self.state = State.WELCOME
                    self.save_state()
    
    def save_state(self):
        """Salva estado no banco de dados"""
        try:
            with get_db_connection() as conn:
                with conn.cursor() as cur:
                    cur.execute("""
                        INSERT INTO questionnaire_state 
                        (sender_id, current_state, current_question_index, phase1_data, 
                         followup_data, trigger_dimensions, attempt_counts, skipped_questions,
                         pre_crisis_state, pre_crisis_question_index, updated_at)
                        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                        ON CONFLICT (sender_id) DO UPDATE SET
                            current_state = EXCLUDED.current_state,
                            current_question_index = EXCLUDED.current_question_index,
                            phase1_data = EXCLUDED.phase1_data,
                            followup_data = EXCLUDED.followup_data,
                            trigger_dimensions = EXCLUDED.trigger_dimensions,
                            attempt_counts = EXCLUDED.attempt_counts,
                            skipped_questions = EXCLUDED.skipped_questions,
                            pre_crisis_state = EXCLUDED.pre_crisis_state,
                            pre_crisis_question_index = EXCLUDED.pre_crisis_question_index,
                            updated_at = EXCLUDED.updated_at
                    """, (
                        self.sender_id,
                        self.state.value,
                        self.current_question_index,
                        json.dumps(self.phase1_data, ensure_ascii=False),
                        json.dumps(self.followup_data, ensure_ascii=False),
                        json.dumps(self.trigger_dimensions, ensure_ascii=False),
                        json.dumps(self.attempt_counts),
                        self.skipped_questions,
                        self.pre_crisis_state.value if self.pre_crisis_state else None,
                        self.pre_crisis_question_index,
                        datetime.utcnow()
                    ))
        except Exception as e:
            print(f"[DB Save State Error] {e}")
            print("[WARNING] N√£o foi poss√≠vel salvar o estado no banco de dados")
    
    def log_interaction(self, message_received: str, message_sent: str, 
                       llm_used: bool = False, safety_triggered: bool = False, 
                       safety_metadata: dict = None, metadata: dict = None):
        """Registra intera√ß√£o no log com campos de seguran√ßa aprimorados"""
        with get_db_connection() as conn:
            with conn.cursor() as cur:
                state_before = self.state.value if self.state else None
                
                # Combina metadados
                full_metadata = metadata or {}
                if safety_metadata:
                    full_metadata['safety'] = safety_metadata
                
                cur.execute("""
                    INSERT INTO questionnaire_logs
                    (sender_id, state_before, state_after, message_received, message_sent, 
                     llm_used, safety_triggered, safety_screening_model, 
                     safety_screening_confidence, safety_detailed_check, metadata)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                """, (
                    self.sender_id,
                    state_before,
                    self.state.value if self.state else None,
                    message_received[:1000],
                    message_sent[:1000],
                    llm_used,
                    safety_triggered,
                    safety_metadata.get('screening_model') if safety_metadata else None,
                    safety_metadata.get('confidence') if safety_metadata else None,
                    safety_metadata.get('detailed_check', False) if safety_metadata else False,
                    json.dumps(full_metadata) if full_metadata else None
                ))
    
    def enter_crisis_mode(self, crisis_type: str, initial_safety_score: int = 3):
        """Entra em modo de crise, salvando estado atual"""
        # Salva estado antes da crise
        self.pre_crisis_state = self.state
        self.pre_crisis_question_index = self.current_question_index
        
        # Muda para estado de emerg√™ncia
        self.state = State.EMERGENCY
        
        # Cria gerenciador de crise SEM carregar estado existente (√© uma nova crise)
        self.crisis_manager = CrisisManager(self.sender_id, load_existing=False)
        self.crisis_manager.crisis_type = crisis_type
        self.crisis_manager.safety_score = initial_safety_score
        # Salva o estado inicial da crise
        self.crisis_manager.save_crisis_state()
        
        self.save_state()
    
    def exit_crisis_mode(self):
        """Sai do modo de crise e retorna ao question√°rio"""
        if self.pre_crisis_state:
            # Restaura estado anterior
            self.state = self.pre_crisis_state
            self.current_question_index = self.pre_crisis_question_index
            self.pre_crisis_state = None
            self.pre_crisis_question_index = None
        else:
            # Se n√£o tinha estado anterior, vai para welcome
            self.state = State.WELCOME
            self.current_question_index = 0
        
        self.crisis_manager = None
        self.save_state()
    
    def reset(self):
        """Reinicia question√°rio"""
        with get_db_connection() as conn:
            with conn.cursor() as cur:
                # Remove estado do question√°rio
                cur.execute("DELETE FROM questionnaire_state WHERE sender_id = %s", (self.sender_id,))
                # Remove estado de crise se existir
                cur.execute("UPDATE crisis_state SET active = false, resolution_reason = 'reset_questionnaire', resolved_at = %s WHERE sender_id = %s AND active = true", (datetime.utcnow(), self.sender_id))
        
        self.state = State.WELCOME
        self.current_question_index = 0
        self.phase1_data = []
        self.followup_data = {"aprofundamento": [], "origem_riscos": {}}
        self.trigger_dimensions = []
        self.attempt_counts = {}
        self.skipped_questions = 0
        self.pre_crisis_state = None
        self.pre_crisis_question_index = None
        self.crisis_manager = None
        self.save_state()
    
    def format_question(self, question: dict, position: int = None, total: int = None) -> str:
        """Formata pergunta para WhatsApp - vers√£o otimizada"""
        qtype = question.get('type', 'text')
        text = question.get('question', '')
        
        # Barra de progresso visual
        progress_bar = ""
        if position and total:
            percentage = int((position / total) * 100)
            filled = int(percentage / 10)  # Divide por 10 para ter 10 blocos
            empty = 10 - filled
            progress_bar = f"{'‚ñì' * filled}{'‚ñë' * empty} {percentage}%\n"
            
            # Adiciona indicador de se√ß√£o
            if position == 1:
                progress_bar = f"üöÄ *Iniciando question√°rio*\n{progress_bar}"
            elif position == total:
                progress_bar = f"üèÅ *√öltima pergunta!*\n{progress_bar}"
            elif position == total // 2:
                progress_bar = f"‚≠ê *Metade do caminho!*\n{progress_bar}"
            
            text = f"*Pergunta {position} de {total}*\n{progress_bar}\n*{text}*"
        else:
            text = f"*{text}*"
        
        # Adiciona formata√ß√£o baseada no tipo (sem linhas divis√≥rias)
        if qtype == 'likert':
            text += "\n\n"
            text += "1Ô∏è‚É£ üòû Discordo totalmente\n"
            text += "2Ô∏è‚É£ üôÅ Discordo\n"
            text += "3Ô∏è‚É£ üòê Neutro\n"
            text += "4Ô∏è‚É£ üôÇ Concordo\n"
            text += "5Ô∏è‚É£ üòÑ Concordo totalmente"
            text += "\n\nüí° _Responda com n√∫mero, texto ou √°udio_ üé§"
        elif qtype == 'multiple choice':
            text += "\n"
            options = question.get('options', [])
            # Usa emojis de n√∫meros (agora suportados no parser!)
            number_emojis = ['1Ô∏è‚É£', '2Ô∏è‚É£', '3Ô∏è‚É£', '4Ô∏è‚É£', '5Ô∏è‚É£', '6Ô∏è‚É£', '7Ô∏è‚É£', '8Ô∏è‚É£', '9Ô∏è‚É£']
            for i, opt in enumerate(options):
                if i < len(number_emojis):
                    text += f"\n{number_emojis[i]} {opt}"
                else:
                    text += f"\n{i+1}) {opt}"
            text += "\n\nüí° _Responda com n√∫mero, texto ou √°udio_ üé§"
        elif qtype == 'text':
            text += "\n\n‚úçÔ∏è _Digite sua resposta livremente_"
            text += "\n\nüí° _Responda com texto ou √°udio_ üé§"
        
        return text
    
    def format_followup_question(self, question: dict, position: int, total: int) -> str:
        """Formata pergunta de follow-up - vers√£o otimizada"""
        # Barra de progresso para follow-up
        percentage = int((position / total) * 100)
        filled = int(percentage / 10)
        empty = 10 - filled
        progress_bar = f"{'‚ñì' * filled}{'‚ñë' * empty} {percentage}%"
        
        text = f"üîç *Aprofundamento {position}/{total}*\n"
        text += f"{progress_bar}\n\n"
        text += f"*{question['question']}*\n"
        
        options = question.get('options', [])
        number_emojis = ['1Ô∏è‚É£', '2Ô∏è‚É£', '3Ô∏è‚É£']
        for i, opt in enumerate(options):
            if i < len(number_emojis):
                text += f"\n{number_emojis[i]} {opt}"
            else:
                text += f"\n{i+1}) {opt}"
        
        text += "\n\nüí° _Responda com n√∫mero, texto ou √°udio_ üé§"
        return text
    
    def format_origin_question(self, question: dict, position: int, total: int, dimension_desc: str = None) -> str:
        """Formata pergunta de origem dos riscos - vers√£o otimizada"""
        # Barra de progresso
        percentage = int((position / total) * 100)
        filled = int(percentage / 10)
        empty = 10 - filled
        progress_bar = f"{'‚ñì' * filled}{'‚ñë' * empty} {percentage}%"
        
        text = f"üîç *Origem dos Riscos {position}/{total}*\n"
        text += f"{progress_bar}\n\n"
        
        # Se tem descri√ß√£o da dimens√£o, adiciona
        if dimension_desc:
            text += f"‚ö†Ô∏è _Riscos identificados {dimension_desc}_\n\n"
        
        text += f"*{question['question']}*"
        
        # Formata baseado no tipo
        if question.get('type') == 'multiple choice':
            text += "\n"
            options = question.get('options', [])
            number_emojis = ['1Ô∏è‚É£', '2Ô∏è‚É£', '3Ô∏è‚É£', '4Ô∏è‚É£']
            for i, opt in enumerate(options):
                if i < len(number_emojis):
                    text += f"\n{number_emojis[i]} {opt}"
                else:
                    text += f"\n{i+1}) {opt}"
            text += "\n\nüí° _Responda com n√∫mero, texto ou √°udio_ üé§"
        else:
            text += "\n\n‚úçÔ∏è _Digite sua resposta livremente_"
            text += "\n\nüí° _Responda com texto ou √°udio_ üé§"
        
        return text
    
    def get_welcome_message(self) -> str:
        """Mensagem de boas-vindas"""
        return """üëã Ol√°! Somos da Vocal Silence e queremos ouvir como voc√™ se sente no ambiente de trabalho.

Este √© um question√°rio psicossocial que vai mapear fatores que impactam seu dia a dia e, com isso, oferecer subs√≠dios para que sua empresa construa planos de a√ß√£o orientados por dados.

üîí Suas respostas s√£o an√¥nimas e tratadas com sigilo.
‚è±Ô∏è Em poucos minutos voc√™ contribui para mudan√ßas reais.
üìå A participa√ß√£o √© volunt√°ria ‚Äì voc√™ pode parar a qualquer momento.
‚öïÔ∏è Importante: este question√°rio n√£o √© avalia√ß√£o m√©dica e n√£o fornece diagn√≥stico.

üëâ Podemos come√ßar?"""
    
    def handle_consent(self, message: str) -> str:
        """Processa consentimento"""
        normalized = ResponseParser.normalize(message)
        
        if any(word in normalized for word in ['sim', 'yes', 'ok', 'vamos', 'pode', 'aceito', 'concordo']):
            self.state = State.PHASE1_QUESTIONS
            self.save_state()
            
            # Explica Likert antes da primeira pergunta
            intro = "√ìtimo! Vamos come√ßar.\n\n"
            intro += "üìä Algumas perguntas usam uma escala de 1 a 5:\n"
            intro += "‚Ä¢ 1 = Discordo totalmente\n‚Ä¢ 5 = Concordo totalmente\n"
            intro += "Voc√™ pode responder com n√∫mero, emoji ou texto.\n\n"
            
            # Primeira pergunta
            question = self.questionnaire[0]
            self.phase1_data = [question.copy()]
            intro += self.format_question(question, 1, len(self.questionnaire))
            
            return intro
        
        elif any(word in normalized for word in ['nao', 'n√£o', 'no', 'depois', 'pare']):
            self.reset()
            return "Sem problemas! Quando quiser participar, √© s√≥ enviar uma mensagem. At√© logo!"
        
        else:
            return "Por favor, responda 'sim' para come√ßar ou 'n√£o' para cancelar."
    
    def handle_phase1_question(self, message: str) -> Tuple[str, bool]:
        """Processa resposta da Fase 1 com an√°lise inteligente"""
        if self.current_question_index >= len(self.questionnaire):
            self.state = State.ASSESSMENT
            self.save_state()
            return self.do_assessment()
        
        question = self.phase1_data[self.current_question_index]
        qtype = question.get('type', 'text')
        required = question.get('required', False)
        
        # Identifica ID da pergunta para contar tentativas
        q_id = f"q_{question.get('id', self.current_question_index)}"
        self.attempt_counts[q_id] = self.attempt_counts.get(q_id, 0) + 1
        attempts = self.attempt_counts[q_id]
        
        # Rastreia esclarecimentos separadamente
        clarification_key = f"{q_id}_clarifications"
        clarification_count = self.attempt_counts.get(clarification_key, 0)
        
        # Parse da resposta
        parsed = None
        llm_used = False
        
        if qtype == 'multiple choice':
            parsed = ResponseParser.parse_multiple_choice(message, question.get('options', []))
        elif qtype == 'likert':
            parsed = ResponseParser.parse_likert(message)
        else:
            parsed = ResponseParser.parse_text(message)
        
        # Se falhou o parse r√°pido, usa LLM
        if not parsed.get('success'):
            attempt_context = {
                'clarification_count': clarification_count,
                'skipped_questions': self.skipped_questions
            }
            parsed = ResponseParser.llm_parse(message, question, attempt_context)
            llm_used = parsed.get('llm_used', False)
            
            # Se foi identificado como tentativa de pular
            if parsed.get('wants_to_skip'):
                if required:
                    # Pergunta obrigat√≥ria - n√£o pode pular
                    return (f"‚ö†Ô∏è Esta pergunta √© obrigat√≥ria e n√£o pode ser pulada.\n\n" +
                           f"Por favor, responda para continuar:\n" +
                           self.format_question(question, self.current_question_index + 1, len(self.questionnaire)),
                           llm_used)
                else:
                    # Pergunta opcional - pode pular mas com limite
                    if self.skipped_questions >= 5:
                        # J√° atingiu o limite
                        self.reset()
                        return ("‚ùå Voc√™ j√° pulou o m√°ximo de 5 perguntas permitidas. " +
                               "O question√°rio ser√° reiniciado para garantir dados consistentes. " +
                               "Digite qualquer mensagem para come√ßar novamente.", llm_used)
                    else:
                        # Ainda pode pular
                        remaining_skips = 5 - self.skipped_questions - 1
                        question['response'] = None
                        question['desconsiderada'] = True
                        self.skipped_questions += 1
                        self.current_question_index += 1
                        
                        # Adiciona pr√≥xima pergunta se existir
                        if self.current_question_index < len(self.questionnaire):
                            if self.current_question_index >= len(self.phase1_data):
                                next_q = self.questionnaire[self.current_question_index].copy()
                                self.phase1_data.append(next_q)
                        
                        self.save_state()
                        
                        # Verifica se terminou o question√°rio
                        if self.current_question_index >= len(self.questionnaire):
                            self.state = State.ASSESSMENT
                            self.save_state()
                            return (self.do_assessment(), llm_used)
                        
                        # Mensagem informativa sobre o limite
                        skip_info = ""
                        if remaining_skips > 0:
                            skip_info = f"\nüí° Voc√™ ainda pode pular {remaining_skips} pergunta{'s' if remaining_skips > 1 else ''}."
                        else:
                            skip_info = "\n‚ö†Ô∏è Aten√ß√£o: Voc√™ atingiu o limite de perguntas que podem ser puladas. Se ultrapassar o limite, o question√°rio ser√° reiniciado."
                        
                        return (f"‚úî Pergunta pulada.{skip_info}\n\n" +
                               self.format_question(self.questionnaire[self.current_question_index], 
                                                  self.current_question_index + 1, 
                                                  len(self.questionnaire)),
                               llm_used)
            
            # Se foi identificado como pergunta/esclarecimento
            if parsed.get('is_clarification'):
                self.attempt_counts[clarification_key] = clarification_count + 1
                
                if parsed.get('clarification_limit_reached'):
                    # Insiste na resposta
                    return (f"‚ö†Ô∏è {parsed.get('message')}\n\n" + 
                           self.format_question(question, self.current_question_index + 1, len(self.questionnaire)),
                           llm_used)
                
                # Fornece esclarecimento e reapresenta a pergunta
                clarification = parsed.get('clarification_response', 'Vou esclarecer sua d√∫vida.')
                return (f"üí¨ {clarification}\n\nüìù Agora, por favor, responda:\n" +
                       self.format_question(question, self.current_question_index + 1, len(self.questionnaire)),
                       llm_used)
            
            # Se foi identificado como off-topic
            if parsed.get('is_off_topic'):
                return (f"‚ö†Ô∏è {parsed.get('message')}\n\n" +
                       self.format_question(question, self.current_question_index + 1, len(self.questionnaire)),
                       llm_used)
            
            # Se n√£o conseguiu interpretar
            if parsed.get('could_not_interpret'):
                # Conta como tentativa falha
                if required:
                    if attempts >= 5:
                        self.reset()
                        return ("Notamos que algumas respostas parecem inconsistentes. Este question√°rio ajuda a empresa a compreender melhor o ambiente de trabalho. Vamos reinici√°-lo, pois n√£o foi preenchido corretamente. Digite qualquer mensagem para come√ßar novamente.", llm_used)
                    else:
                        return (f"‚ùå {parsed.get('message', 'N√£o consegui entender sua resposta.')}\n\n" +
                               f"(Tentativa {attempts}/5)\n" +
                               self.format_question(question, self.current_question_index + 1, len(self.questionnaire)),
                               llm_used)
                else:
                    if attempts >= 3:
                        # Pula pergunta ap√≥s 3 tentativas
                        question['response'] = None
                        question['desconsiderada'] = True
                        self.skipped_questions += 1
                        
                        if self.skipped_questions >= 5:
                            self.reset()
                            return ("Notamos que muitas perguntas foram puladas e, por isso, n√£o √© poss√≠vel continuar. Este question√°rio ajuda a empresa a compreender melhor o ambiente de trabalho. Vamos reinici√°-lo para que possa ser preenchido corretamente. Digite qualquer mensagem para come√ßar novamente.", llm_used)
                        
                        self.current_question_index += 1
                        
                        if self.current_question_index < len(self.questionnaire):
                            if self.current_question_index >= len(self.phase1_data):
                                next_q = self.questionnaire[self.current_question_index].copy()
                                self.phase1_data.append(next_q)
                        
                        self.save_state()
                        
                        if self.current_question_index >= len(self.questionnaire):
                            self.state = State.ASSESSMENT
                            self.save_state()
                            return (self.do_assessment(), llm_used)
                        
                        return (f"Vamos pular esta pergunta.\n\n" +
                               self.format_question(self.questionnaire[self.current_question_index], 
                                                  self.current_question_index + 1, 
                                                  len(self.questionnaire)),
                               llm_used)
                    else:
                        return (f"‚ùå N√£o consegui entender. Tente responder de forma mais clara.\n\n" +
                               f"(Tentativa {attempts}/3)\n" +
                               self.format_question(question, self.current_question_index + 1, len(self.questionnaire)),
                               llm_used)
        
        # Processa resultado bem-sucedido
        if parsed.get('success'):
            # Valida√ß√£o adicional para multiple choice
            if qtype == 'multiple choice':
                valid_options = question.get('options', [])
                if parsed['value'] not in valid_options:
                    # Resposta inv√°lida - n√£o est√° nas op√ß√µes
                    return (f"‚ùå Resposta inv√°lida. Por favor, escolha uma das op√ß√µes:\n" +
                           self.format_question(question, self.current_question_index + 1, len(self.questionnaire)),
                           llm_used)
            elif qtype == 'likert':
                # Valida se √© um valor v√°lido de Likert (1-5)
                try:
                    likert_value = int(parsed['value'])
                    if likert_value < 1 or likert_value > 5:
                        return (f"‚ùå Resposta inv√°lida. Por favor, escolha um valor de 1 a 5:\n" +
                               self.format_question(question, self.current_question_index + 1, len(self.questionnaire)),
                               llm_used)
                except (ValueError, TypeError):
                    return (f"‚ùå Resposta inv√°lida. Por favor, escolha um valor de 1 a 5:\n" +
                           self.format_question(question, self.current_question_index + 1, len(self.questionnaire)),
                           llm_used)
            
            # Resposta v√°lida - reseta contadores
            question['response'] = parsed['value']
            question['desconsiderada'] = False
            self.attempt_counts[q_id] = 0  # Reset tentativas
            self.attempt_counts[clarification_key] = 0  # Reset esclarecimentos
            
            # Pr√≥xima pergunta
            self.current_question_index += 1
            
            if self.current_question_index >= len(self.questionnaire):
                self.state = State.ASSESSMENT
                self.save_state()
                return (self.do_assessment(), llm_used)
            else:
                # Adiciona pr√≥xima pergunta aos dados
                if self.current_question_index < len(self.questionnaire):
                    next_q = self.questionnaire[self.current_question_index].copy()
                    self.phase1_data.append(next_q)
                
                self.save_state()
                
                # Confirma√ß√£o breve + pr√≥xima pergunta
                confidence_indicator = ""
                if parsed.get('interpretation_confidence'):
                    conf = parsed['interpretation_confidence']
                    if conf < 0.85:
                        confidence_indicator = " (interpretado)"
                
                confirmation = f"‚úî Resposta registrada{confidence_indicator}."
                next_question = self.format_question(
                    self.questionnaire[self.current_question_index],
                    self.current_question_index + 1,
                    len(self.questionnaire)
                )
                
                return (f"{confirmation}\n\n{next_question}", llm_used)
        
        # Fallback - n√£o deveria chegar aqui
        return ("Houve um erro ao processar sua resposta. Por favor, tente novamente.", llm_used)


    def do_assessment(self) -> str:
        """Realiza avalia√ß√£o e determina pr√≥ximos passos"""
        # Calcula m√©dias por dimens√£o
        dimension_scores = {}
        target_dimensions = {
            "Qualidade do sono e disposi√ß√£o",
            "√Çnimo e motiva√ß√£o", 
            "Estresse e ansiedade",
            "Equil√≠brio vida-trabalho",
            "Exig√™ncias de tempo no trabalho"
        }
        
        for item in self.phase1_data:
            if item.get('type', '').lower() == 'likert' and not item.get('desconsiderada'):
                if item.get('response') is not None:
                    dim = item.get('dimension', '')
                    if dim not in dimension_scores:
                        dimension_scores[dim] = []
                    try:
                        dimension_scores[dim].append(float(item['response']))
                    except:
                        pass
        
        # Identifica dimens√µes com risco
        self.trigger_dimensions = []
        for dim, scores in dimension_scores.items():
            if scores and ResponseParser.normalize(dim) in [ResponseParser.normalize(d) for d in target_dimensions]:
                avg = sum(scores) / len(scores)
                if avg <= 3.0:  # ALTO ou MODERADO
                    self.trigger_dimensions.append(dim)
        
        # Salva fase 1
        self._save_to_s3('phase1')
        
        if self.trigger_dimensions:
            self.state = State.FOLLOWUP_QUESTIONS  # Vai direto para FOLLOWUP_QUESTIONS
            self.current_question_index = 0  # Inicializa o √≠ndice
            self.save_state()
            # Retorna lista com duas mensagens: introdu√ß√£o + primeira pergunta
            q = FOLLOWUP_QUESTIONS[0]
            return [
                "Percebemos alguns sinais de risco nesta etapa. "
                "Vamos fazer algumas perguntas de aprofundamento para entender melhor o que est√° acontecendo.",
                self.format_followup_question(q, 1, 6)
            ]
        else:
            # Sem riscos, finaliza
            self.state = State.COMPLETION
            self.save_state()
            return self.get_completion_message()
    
    def handle_followup_questions(self, message: str) -> Tuple[str, bool]:
        """Processa perguntas de follow-up com an√°lise inteligente"""
        llm_used = False
        
        if self.current_question_index < len(FOLLOWUP_QUESTIONS):
            question = FOLLOWUP_QUESTIONS[self.current_question_index]
            
            # Rastreia esclarecimentos
            q_id = f"followup_{question['id']}"
            clarification_key = f"{q_id}_clarifications"
            clarification_count = self.attempt_counts.get(clarification_key, 0)
            
            parsed = ResponseParser.parse_multiple_choice(message, question['options'])
            
            if not parsed.get('success'):
                # Cria estrutura de pergunta compat√≠vel
                question_dict = {
                    'type': 'multiple choice',
                    'options': question['options'],
                    'question': question['question']
                }
                attempt_context = {'clarification_count': clarification_count}
                parsed = ResponseParser.llm_parse(message, question_dict, attempt_context)
                llm_used = True
                
                # Processa esclarecimentos
                if parsed.get('is_clarification'):
                    self.attempt_counts[clarification_key] = clarification_count + 1
                    
                    if parsed.get('clarification_limit_reached'):
                        return (f"‚ö†Ô∏è {parsed.get('message')}\n\n" +
                               self.format_followup_question(question, self.current_question_index + 1, 6),
                               llm_used)
                    
                    clarification = parsed.get('clarification_response', '')
                    return (f"üí¨ {clarification}\n\nüìù Por favor, responda:\n" +
                           self.format_followup_question(question, self.current_question_index + 1, 6),
                           llm_used)
                
                if parsed.get('is_off_topic'):
                    return (f"‚ö†Ô∏è {parsed.get('message')}\n\n" +
                           self.format_followup_question(question, self.current_question_index + 1, 6),
                           llm_used)
            
            if parsed.get('success'):
                # Valida√ß√£o adicional: verifica se o valor est√° realmente nas op√ß√µes
                if parsed['value'] not in question['options']:
                    # Resposta inv√°lida
                    return (f"‚ùå Resposta inv√°lida. Por favor, escolha uma das op√ß√µes:\n" +
                           self.format_followup_question(question, self.current_question_index + 1, 6),
                           llm_used)
                
                # Salva resposta
                q_copy = question.copy()
                q_copy['response'] = parsed['value']
                self.followup_data['aprofundamento'].append(q_copy)
                
                # Reseta contadores
                self.attempt_counts[clarification_key] = 0
                
                self.current_question_index += 1
                self.save_state()
                
                if self.current_question_index >= len(FOLLOWUP_QUESTIONS):
                    # Passa diretamente para ORIGIN_QUESTIONS
                    self.state = State.ORIGIN_QUESTIONS  # Vai direto para ORIGIN_QUESTIONS
                    self.current_question_index = 0
                    self.save_state()
                    # Retorna lista com duas mensagens: introdu√ß√£o + primeira pergunta de origem
                    dim = self.trigger_dimensions[0] if self.trigger_dimensions else "Risco identificado"
                    dim_description = DIMENSION_DESCRIPTIONS.get(dim, dim)
                    q = ORIGIN_QUESTIONS[0]
                    question_text = f"üîç *Foram encontrados riscos {dim_description}*\n\n"
                    question_text += f"*1/{len(self.trigger_dimensions)*2} ‚Äì {q['question']}*"
                    for i, opt in enumerate(q['options'], 1):
                        question_text += f"\n{i}) {opt}"
                    return ([
                        "Vamos fazer algumas outras perguntas para entender melhor a origem destes riscos.",
                        question_text
                    ], llm_used)
                else:
                    next_q = FOLLOWUP_QUESTIONS[self.current_question_index]
                    return (f"‚úî Registrado.\n\n{self.format_followup_question(next_q, self.current_question_index + 1, 6)}", llm_used)
            else:
                # Usa as op√ß√µes da pergunta atual
                if self.current_question_index < len(FOLLOWUP_QUESTIONS):
                    current_q = FOLLOWUP_QUESTIONS[self.current_question_index]
                    options = current_q.get('options', [])
                    if options:
                        options_text = " ou ".join([f"'{opt}'" for opt in options])
                        return (f"Por favor, responda {options_text}.", llm_used)
                return ("Por favor, responda com uma das op√ß√µes apresentadas.", llm_used)
        
        return ("", llm_used)
    
    def handle_origin_questions(self, message: str) -> Tuple[str, bool]:
        """Processa perguntas de origem com as NOVAS perguntas (2 por dimens√£o)"""
        # Determina qual dimens√£o e pergunta atual
        dim_index = self.current_question_index // 2  # Mudado de 3 para 2
        q_index = self.current_question_index % 2    # Mudado de 3 para 2
        
        if dim_index >= len(self.trigger_dimensions):
            # Finaliza
            self._save_to_s3('followups')
            self.state = State.COMPLETION
            self.save_state()
            return (self.get_completion_message(), False)
        
        current_dim = self.trigger_dimensions[dim_index]
        question = ORIGIN_QUESTIONS[q_index]
        
        # Parse da resposta baseado no tipo
        llm_used = False
        if q_index == 0:  # Primeira pergunta (multiple choice)
            parsed = ResponseParser.parse_multiple_choice(message, question['options'])
            
            if not parsed.get('success'):
                # Usa LLM para tentar interpretar
                question_dict = {
                    'type': 'multiple choice',
                    'options': question['options'],
                    'question': question['question']
                }
                parsed = ResponseParser.llm_parse(message, question_dict)
                llm_used = parsed.get('llm_used', False)
                
                if parsed.get('is_clarification'):
                    clarification = parsed.get('clarification_response', '')
                    # Reapresenta a pergunta formatada
                    total_origin = len(self.trigger_dimensions) * 2
                    current_pos = self.current_question_index + 1
                    question_formatted = self.format_origin_question(question, current_pos, total_origin)
                    return (f"üí¨ {clarification}\n\nüìù Por favor, responda:\n{question_formatted}", llm_used)
                
                if not parsed.get('success'):
                    # Mostra op√ß√µes com emojis de n√∫meros
                    return (f"‚ùå Por favor, escolha uma das op√ß√µes:\n\n1Ô∏è‚É£ Do ambiente de trabalho\n2Ô∏è‚É£ Da vida pessoal\n3Ô∏è‚É£ Dos dois\n\nüí° _Responda com n√∫mero, texto ou √°udio_ üé§", llm_used)
            
            response_value = parsed['value']
        else:  # Segunda pergunta (texto livre)
            response_value = message[:500]
        
        # Salva resposta
        if current_dim not in self.followup_data['origem_riscos']:
            self.followup_data['origem_riscos'][current_dim] = []
        
        q_copy = question.copy()
        q_copy['response'] = response_value
        self.followup_data['origem_riscos'][current_dim].append(q_copy)
        
        self.current_question_index += 1
        self.save_state()
        
        # Pr√≥xima pergunta
        new_dim_index = self.current_question_index // 2  # Mudado de 3 para 2
        new_q_index = self.current_question_index % 2     # Mudado de 3 para 2
        
        if new_dim_index >= len(self.trigger_dimensions):
            # Finaliza
            self._save_to_s3('followups')
            self.state = State.COMPLETION
            self.save_state()
            return (self.get_completion_message(), llm_used)
        
        new_dim = self.trigger_dimensions[new_dim_index]
        
        # Prepara mensagem para pr√≥xima pergunta
        next_question = ORIGIN_QUESTIONS[new_q_index]
        total_origin = len(self.trigger_dimensions) * 2  # Mudado de 3 para 2
        current_pos = self.current_question_index + 1
        
        # Usa o novo m√©todo de formata√ß√£o
        if new_q_index == 0:  # Nova dimens√£o - mostra descri√ß√£o
            dim_description = DIMENSION_DESCRIPTIONS.get(new_dim, new_dim)
            question_text = self.format_origin_question(next_question, current_pos, total_origin, dim_description)
        else:
            question_text = self.format_origin_question(next_question, current_pos, total_origin)
        
        return (f"‚úî Registrado.\n\n{question_text}", llm_used)
    
    def _save_to_s3(self, phase: str):
        """Salva dados no S3"""
        timestamp = datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')
        
        if phase == 'phase1':
            data = {"questionnaire": self.phase1_data}
            key = f"questionario_state_machine/{self.sender_id}/{timestamp}/phase1.json"
        else:
            data = self.followup_data
            key = f"questionario_state_machine/{self.sender_id}/{timestamp}/followups.json"
        
        s3.put_object(
            Bucket=S3_BUCKET,
            Key=key,
            Body=json.dumps(data, ensure_ascii=False).encode('utf-8'),
            ContentType="application/json; charset=utf-8"
        )
    
    def get_completion_message(self) -> str:
        """Mensagem de conclus√£o"""
        self.reset()  # Limpa estado
        return ("‚ú® Question√°rio conclu√≠do! Agradecemos imensamente sua participa√ß√£o e confian√ßa. "
               "Suas respostas foram registradas com sucesso e ser√£o tratadas com total confidencialidade. "
               "Agora vamos apagar o hist√≥rico desta conversa para garantir sua privacidade. Muito obrigado! üôè")
    
    def get_resume_questionnaire_message(self) -> str:
        """Mensagem ao retomar question√°rio ap√≥s crise"""
        current_state_messages = {
            State.PHASE1_QUESTIONS: "Vamos continuar o question√°rio de onde paramos.",
            State.FOLLOWUP_QUESTIONS: "Vamos continuar com as perguntas de aprofundamento.",
            State.ORIGIN_QUESTIONS: "Vamos continuar explorando as origens dos riscos identificados.",
        }
        
        base_msg = "Que bom que voc√™ est√° melhor! üíö\n\n"
        state_msg = current_state_messages.get(self.state, "Vamos continuar de onde paramos.")
        
        print(f"[Resume] Estado atual: {self.state}, √≠ndice: {self.current_question_index}")
        
        # Reapresenta a √∫ltima pergunta
        if self.state == State.PHASE1_QUESTIONS:
            if self.current_question_index < len(self.questionnaire):
                question = self.questionnaire[self.current_question_index]
                question_text = self.format_question(
                    question,
                    self.current_question_index + 1,
                    len(self.questionnaire)
                )
                print(f"[Resume] Pergunta Phase1: {self.current_question_index + 1}/{len(self.questionnaire)}")
                return f"{base_msg}{state_msg}\n\n{question_text}"
            else:
                print(f"[Resume] √çndice Phase1 inv√°lido: {self.current_question_index}/{len(self.questionnaire)}")
        
        elif self.state == State.FOLLOWUP_QUESTIONS:
            if self.current_question_index < len(FOLLOWUP_QUESTIONS):
                question = FOLLOWUP_QUESTIONS[self.current_question_index]
                print(f"[Resume] Pergunta Followup: {self.current_question_index + 1}/6")
                return f"{base_msg}{state_msg}\n\n{self.format_followup_question(question, self.current_question_index + 1, 6)}"
            else:
                print(f"[Resume] √çndice Followup inv√°lido: {self.current_question_index}/6")
        
        elif self.state == State.ORIGIN_QUESTIONS:
            dim_index = self.current_question_index // 2  # Mudado de 3 para 2
            q_index = self.current_question_index % 2    # Mudado de 3 para 2
            if dim_index < len(self.trigger_dimensions):
                dim = self.trigger_dimensions[dim_index]
                # Obt√©m descri√ß√£o detalhada da dimens√£o
                dim_description = DIMENSION_DESCRIPTIONS.get(dim, dim)
                question = ORIGIN_QUESTIONS[q_index]
                total = len(self.trigger_dimensions) * 2  # Mudado de 3 para 2
                current_pos = self.current_question_index + 1
                
                if q_index == 0:
                    prefix = f"üîç *Foram encontrados riscos {dim_description}*\n\n"
                else:
                    prefix = ""
                
                # Formata pergunta baseado no tipo
                if question.get('type') == 'multiple choice':
                    question_text = f"*{current_pos}/{total} ‚Äì {question['question']}*"
                    for i, opt in enumerate(question['options'], 1):
                        question_text += f"\n{i}) {opt}"
                else:
                    question_text = f"*{current_pos}/{total} ‚Äì {question['question']}*"
                
                print(f"[Resume] Pergunta Origin: {current_pos}/{total}, dim={dim}")
                return f"{base_msg}{state_msg}\n\n{prefix}{question_text}"
            else:
                print(f"[Resume] √çndice Origin inv√°lido: dim_index={dim_index}, trigger_dimensions={len(self.trigger_dimensions)}")
        
        elif self.state == State.CONSENT:
            print(f"[Resume] Retornando para consentimento")
            return f"{base_msg}Vamos retomar onde paramos.\n\n{self.get_welcome_message()}"
            
        else:
            print(f"[Resume] Estado n√£o tratado: {self.state}")
            # Fallback - volta para o in√≠cio se estado desconhecido
            self.state = State.WELCOME
            self.current_question_index = 0
            self.save_state()
            return f"{base_msg}Vamos reiniciar o question√°rio.\n\n{self.get_welcome_message()}"
        
        # Garante que sempre retorna algo
        return f"{base_msg}{state_msg}"
    
    def process_message(self, message: str, audio_info: Dict[str, Any] = None) -> str:
        """Processa mensagem e retorna resposta (texto ou √°udio transcrito)"""
        llm_used = False
        safety_triggered = False
        safety_metadata = {}
        audio_transcription = None
        
        # Se recebeu √°udio, processa transcri√ß√£o PRIMEIRO
        if audio_info and audio_info.get('media_url'):
            # Determina tipo da pergunta atual para valida√ß√£o de dura√ß√£o
            current_question_type = "text"  # Padr√£o
            
            if self.state == State.PHASE1_QUESTIONS:
                if self.current_question_index < len(self.questionnaire):
                    current_question_type = self.questionnaire[self.current_question_index].get('type', 'text')
            elif self.state == State.FOLLOWUP_QUESTIONS:
                current_question_type = "multiple choice"  # Follow-up s√£o sempre multiple choice
            elif self.state == State.ORIGIN_QUESTIONS:
                q_index = self.current_question_index % 2
                if q_index == 0:
                    current_question_type = "multiple choice"
                else:
                    current_question_type = "text"
            
            print(f"[Audio] Processando √°udio para pergunta tipo: {current_question_type}")
            
            # Processa o √°udio
            audio_result = AudioTranscriber.process_audio_message(
                audio_info['media_url'],
                audio_info.get('media_content_type', 'audio/ogg'),
                current_question_type
            )
            
            if not audio_result['success']:
                # Retorna mensagem de erro espec√≠fica do √°udio (dura√ß√£o, etc)
                self.log_interaction(
                    f"[AUDIO: {audio_info['media_url'][:50]}...]",
                    audio_result['message'],
                    False, False, {"audio_error": True, "error": audio_result.get('error')}
                )
                return audio_result['message']
            
            # IMPORTANTE: Substitui a mensagem pela transcri√ß√£o
            # A partir daqui, tudo funciona como se fosse texto normal
            audio_transcription = audio_result['transcription']
            message = audio_transcription  # Substitui completamente a mensagem
            
            # Adiciona metadados do √°udio para o log
            safety_metadata['audio_processed'] = True
            safety_metadata['audio_duration'] = audio_result.get('duration')
            safety_metadata['audio_language'] = audio_result.get('language')
            
            print(f"[Audio] Transcri√ß√£o substituiu mensagem: {message[:100]}...")
        
        # ==== A PARTIR DAQUI, TUDO FUNCIONA NORMALMENTE ====
        # A mensagem agora √© o texto (original ou transcrito do √°udio)
        # TODA a l√≥gica abaixo aplica-se igualmente para texto e √°udio:
        # - Detec√ß√£o de comandos especiais (reiniciar, etc)
        # - Modo de emerg√™ncia/crise
        # - Triagem de seguran√ßa (SafetyProtocol)
        # - Possibilidade de pular perguntas
        # - Uso de LLM para interpretar respostas amb√≠guas
        # - Toda a m√°quina de estados do question√°rio
        
        # Verifica comandos especiais primeiro (mesmo durante crise)
        normalized_msg = ResponseParser.normalize(message)
        if any(word in normalized_msg for word in ['reiniciar', 'recomecar', 'reset', 'restart']):
            # Se estava em crise, registra o motivo da interrup√ß√£o
            if self.state == State.EMERGENCY and self.crisis_manager:
                self.log_interaction(message, "Reinicializa√ß√£o solicitada durante crise", False, True, 
                                   {"crisis_interrupted": True, "reason": "user_reset_request"})
            self.reset()
            return "üîÑ Question√°rio reiniciado. Se quiser come√ßar novamente, √© s√≥ falar um Ol√°!\n\n"
        
        # Se est√° em modo de emerg√™ncia/crise
        if self.state == State.EMERGENCY:
            # Garante que o crisis_manager existe
            if not self.crisis_manager:
                # Tenta carregar gerenciador existente
                self.crisis_manager = CrisisManager(self.sender_id, load_existing=True)
                # Se n√£o conseguiu carregar do banco ou tipo est√° vazio, define um tipo padr√£o
                if not self.crisis_manager.crisis_type:
                    self.crisis_manager.crisis_type = 'unknown'
                    print(f"[Emergency] Crisis type estava None/vazio, definindo como 'unknown'")
                    # Salva o estado corrigido
                    self.crisis_manager.save_crisis_state()
                print(f"[Emergency] Gerenciador de crise carregado/criado para usu√°rio em emerg√™ncia: {self.sender_id}, tipo: {self.crisis_manager.crisis_type}")
            
            print(f"[Emergency] Processando mensagem de crise: {len(message)} caracteres")
            # Gerencia conversa de crise
            response, can_resume, crisis_metadata = self.crisis_manager.handle_crisis_conversation(message)
            
            # Log da intera√ß√£o
            self.log_interaction(message, response, True, True, crisis_metadata)
            
            # Se pode retomar question√°rio
            if can_resume:
                print(f"[Emergency] Can resume=True. Retomando question√°rio.")
                print(f"[Emergency] Estado anterior: {self.pre_crisis_state}, √≠ndice: {self.pre_crisis_question_index}")
                print(f"[Emergency] Resposta antes da retomada: '{response[:100]}'")
                
                self.exit_crisis_mode()
                resume_message = self.get_resume_questionnaire_message()
                
                print(f"[Emergency] Mensagem de retomada gerada: {len(resume_message)} caracteres")
                print(f"[Emergency] Primeiros 100 chars da mensagem de retomada: '{resume_message[:100]}'")
                
                # Combina resposta da crise com mensagem de retomada
                if response:
                    response += f"\n\n{resume_message}"
                else:
                    response = resume_message
                    
                print(f"[Emergency] Resposta final (primeiros 200 chars): '{response[:200]}'")
            
            return response
        
        # 1. SEMPRE faz triagem inicial com LLM
        print(f"[Safety] Iniciando triagem de seguran√ßa para: {message[:50]}...")
        screening_result = SafetyProtocol.llm_screening(message)
        
        safety_metadata = {
            'screening_model': screening_result.get('screening_model'),
            'confidence': screening_result.get('confidence'),
            'type': screening_result.get('type'),
            'detailed_check': False
        }
        
        # 2. Se detectou risco acima do limiar, faz verifica√ß√£o detalhada
        if screening_result.get('has_risk') and screening_result.get('confidence', 0) >= SAFETY_CONFIDENCE_THRESHOLD:
            print(f"[Safety] Risco detectado ({screening_result['type']}, confian√ßa: {screening_result['confidence']:.2f}). Fazendo verifica√ß√£o detalhada...")
            
            # Verifica√ß√£o detalhada com modelo avan√ßado
            detailed_result = SafetyProtocol.llm_detailed_check(message, screening_result)
            safety_metadata['detailed_check'] = True
            safety_metadata['severity'] = detailed_result.get('severity')
            safety_metadata['detailed_model'] = detailed_result.get('detailed_check_model')
            
            # Se confirmou emerg√™ncia, entra em modo de crise
            if detailed_result.get('is_emergency') and detailed_result.get('confidence', 0) > 0.6:
                self.enter_crisis_mode(
                    crisis_type=detailed_result.get('type'),
                    initial_safety_score=detailed_result.get('initial_safety_score', 3)
                )
                
                # Primeira resposta da crise
                response, can_resume, crisis_metadata = self.crisis_manager.handle_crisis_conversation(message)
                safety_triggered = True
                
                # Combina metadados
                combined_metadata = {**safety_metadata, **crisis_metadata}
                
                # Log com todos os detalhes
                self.log_interaction(message, response, True, True, combined_metadata)
                return response
        
        # 3. Processa baseado no estado atual (fluxo normal)
        try:
            response = ""
            
            if self.state == State.WELCOME:
                response = self.get_welcome_message()
                self.state = State.CONSENT
                
            elif self.state == State.CONSENT:
                response = self.handle_consent(message)
                
            elif self.state == State.PHASE1_QUESTIONS:
                response, llm_used = self.handle_phase1_question(message)
                
            elif self.state == State.ASSESSMENT:
                response = self.do_assessment()
                
            elif self.state == State.FOLLOWUP_INTRO:
                # Este estado n√£o deve mais ser usado, mas mantido por compatibilidade
                # Vai direto para FOLLOWUP_QUESTIONS
                self.state = State.FOLLOWUP_QUESTIONS
                self.current_question_index = 0
                q = FOLLOWUP_QUESTIONS[0]
                response = [
                    "Percebemos alguns sinais de risco nesta etapa. "
                    "Vamos fazer algumas perguntas de aprofundamento para entender melhor o que est√° acontecendo.",
                    self.format_followup_question(q, 1, 6)
                ]
                
            elif self.state == State.FOLLOWUP_QUESTIONS:
                response, llm_used = self.handle_followup_questions(message)
                
            elif self.state == State.ORIGIN_INTRO:
                # Este estado n√£o deve mais ser usado, mas mantido por compatibilidade
                # Vai direto para ORIGIN_QUESTIONS
                self.state = State.ORIGIN_QUESTIONS
                self.current_question_index = 0
                dim = self.trigger_dimensions[0] if self.trigger_dimensions else "Risco identificado"
                dim_description = DIMENSION_DESCRIPTIONS.get(dim, dim)
                q = ORIGIN_QUESTIONS[0]
                question_text = f"üîç *Foram encontrados riscos {dim_description}*\n\n"
                question_text += f"*1/{len(self.trigger_dimensions)*2} ‚Äì {q['question']}*"
                for i, opt in enumerate(q['options'], 1):
                    question_text += f"\n{i}) {opt}"
                response = [
                    "Vamos fazer algumas outras perguntas para entender melhor a origem destes riscos.",
                    question_text
                ]
                
            elif self.state == State.ORIGIN_QUESTIONS:
                response, llm_used = self.handle_origin_questions(message)
                
            elif self.state == State.COMPLETION:
                response = self.get_completion_message()
            
            self.save_state()
            # Se response \u00e9 uma lista, converte para string para o log
            log_response = response
            if isinstance(response, list):
                log_response = " | ".join(response)  # Junta as mensagens com separador para o log
            
            # Se foi √°udio, adiciona indicador no log e resposta
            log_message = message
            if audio_transcription:
                log_message = f"[√ÅUDIO TRANSCRITO]: {audio_transcription}"
                # Adiciona confirma√ß√£o de transcri√ß√£o na resposta se n√£o for erro/crise
                if not safety_triggered and self.state not in [State.EMERGENCY, State.COMPLETION, State.RESET]:
                    if isinstance(response, list):
                        response[0] = f"üé§ *Entendi seu √°udio:* \"{audio_transcription[:100]}{'...' if len(audio_transcription) > 100 else ''}\"\n\n{response[0]}"
                    else:
                        response = f"üé§ *Entendi seu √°udio:* \"{audio_transcription[:100]}{'...' if len(audio_transcription) > 100 else ''}\"\n\n{response}"
            
            self.log_interaction(log_message, log_response, llm_used, safety_triggered, safety_metadata)
            return response
            
        except Exception as e:
            print(f"[State Machine Error] {e}")
            self.log_interaction(message, "[ERROR]", False, False, safety_metadata, {"error": str(e)})
            return "Desculpe, houve um erro tempor√°rio. Pode repetir sua √∫ltima mensagem?"

# =========================
# Classe para Transcri√ß√£o de √Åudio
# =========================
class AudioTranscriber:
    """Gerencia transcri√ß√£o de √°udios do WhatsApp"""
    
    @staticmethod
    def get_audio_duration_from_url(media_url: str, account_sid: str, auth_token: str) -> float:
        """Obt√©m dura√ß√£o aproximada do √°udio sem baixar completamente"""
        try:
            # Faz requisi√ß√£o HEAD para obter tamanho do arquivo
            response = requests.head(
                media_url,
                auth=(account_sid, auth_token),
                timeout=5
            )
            
            # Estima dura√ß√£o baseado no tamanho (aproxima√ß√£o para √°udio do WhatsApp)
            # WhatsApp usa OPUS codec ~6KB/s para voz
            content_length = int(response.headers.get('Content-Length', 0))
            if content_length > 0:
                estimated_duration = content_length / 6000  # 6KB por segundo
                return estimated_duration
            
            # Se n√£o conseguir estimar, retorna dura√ß√£o m√°xima para for√ßar download
            return MAX_AUDIO_DURATION_TEXT
            
        except Exception as e:
            print(f"[Audio Duration Error] {e}")
            return MAX_AUDIO_DURATION_TEXT
    
    @staticmethod
    def download_audio(media_url: str, account_sid: str, auth_token: str) -> bytes:
        """Baixa arquivo de √°udio do Twilio"""
        try:
            response = requests.get(
                media_url,
                auth=(account_sid, auth_token),
                timeout=30
            )
            response.raise_for_status()
            return response.content
        except Exception as e:
            print(f"[Audio Download Error] {e}")
            raise
    
    @staticmethod
    def transcribe_audio(audio_content: bytes, media_content_type: str = "audio/ogg") -> Dict[str, Any]:
        """Transcreve √°udio usando OpenAI Whisper"""
        try:
            # Determina extens√£o baseado no content type
            extension = ".ogg"  # Padr√£o do WhatsApp
            if "mpeg" in media_content_type.lower():
                extension = ".mp3"
            elif "mp4" in media_content_type.lower():
                extension = ".mp4"
            elif "wav" in media_content_type.lower():
                extension = ".wav"
            
            # Cria arquivo tempor√°rio
            with tempfile.NamedTemporaryFile(suffix=extension, delete=True) as tmp_file:
                tmp_file.write(audio_content)
                tmp_file.flush()
                
                # Transcreve com Whisper
                with open(tmp_file.name, "rb") as audio_file:
                    transcript = client.audio.transcriptions.create(
                        model="whisper-1",
                        file=audio_file,
                        language="pt",  # For√ßa portugu√™s
                        response_format="verbose_json"  # Obt√©m mais informa√ß√µes
                    )
                
                return {
                    "success": True,
                    "text": transcript.text,
                    "duration": transcript.duration if hasattr(transcript, 'duration') else None,
                    "language": transcript.language if hasattr(transcript, 'language') else "pt"
                }
                
        except Exception as e:
            print(f"[Transcription Error] {e}")
            return {
                "success": False,
                "error": str(e),
                "text": None
            }
    
    @staticmethod
    def validate_audio_duration(duration: float, question_type: str) -> Dict[str, Any]:
        """Valida se dura√ß√£o do √°udio est√° dentro dos limites"""
        max_duration = MAX_AUDIO_DURATION_TEXT  # Padr√£o
        
        if question_type == "multiple choice":
            max_duration = MAX_AUDIO_DURATION_MULTIPLE_CHOICE
        elif question_type == "likert":
            max_duration = MAX_AUDIO_DURATION_LIKERT
        elif question_type == "text":
            max_duration = MAX_AUDIO_DURATION_TEXT
        
        if duration > max_duration:
            return {
                "valid": False,
                "message": f"‚ö†Ô∏è √Åudio muito longo ({duration:.0f}s). Para esta pergunta, envie √°udios de at√© {max_duration}s.",
                "max_duration": max_duration
            }
        
        return {
            "valid": True,
            "max_duration": max_duration
        }
    
    @staticmethod
    def process_audio_message(media_url: str, media_content_type: str, 
                            question_type: str = "text") -> Dict[str, Any]:
        """Processa mensagem de √°udio completa"""
        try:
            # Primeiro, estima dura√ß√£o sem baixar
            estimated_duration = AudioTranscriber.get_audio_duration_from_url(
                media_url, TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN
            )
            
            # Valida dura√ß√£o estimada
            duration_check = AudioTranscriber.validate_audio_duration(
                estimated_duration, question_type
            )
            
            # Se dura√ß√£o estimada j√° excede muito o limite, nem baixa
            if not duration_check["valid"] and estimated_duration > duration_check["max_duration"] * 2:
                return {
                    "success": False,
                    "message": duration_check["message"],
                    "transcription": None
                }
            
            # Baixa o √°udio
            print(f"[Audio] Baixando √°udio de {media_url[:50]}...")
            audio_content = AudioTranscriber.download_audio(
                media_url, TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN
            )
            
            # Transcreve
            print(f"[Audio] Transcrevendo √°udio ({len(audio_content)} bytes)...")
            transcription_result = AudioTranscriber.transcribe_audio(
                audio_content, media_content_type
            )
            
            if not transcription_result["success"]:
                return {
                    "success": False,
                    "message": "‚ùå N√£o consegui transcrever o √°udio. Por favor, envie uma mensagem de texto ou tente novamente.",
                    "transcription": None,
                    "error": transcription_result.get("error")
                }
            
            # Valida dura√ß√£o real se dispon√≠vel
            if transcription_result.get("duration"):
                real_duration = transcription_result["duration"]
                duration_check = AudioTranscriber.validate_audio_duration(
                    real_duration, question_type
                )
                
                if not duration_check["valid"]:
                    return {
                        "success": False,
                        "message": duration_check["message"],
                        "transcription": transcription_result["text"],
                        "duration": real_duration
                    }
            
            # Sucesso
            return {
                "success": True,
                "transcription": transcription_result["text"],
                "duration": transcription_result.get("duration"),
                "language": transcription_result.get("language", "pt")
            }
            
        except Exception as e:
            print(f"[Audio Processing Error] {e}")
            return {
                "success": False,
                "message": "‚ùå Erro ao processar √°udio. Por favor, envie uma mensagem de texto.",
                "transcription": None,
                "error": str(e)
            }

# =========================
# Fun√ß√µes auxiliares
# =========================
def _parse_twilio_body(event):
    """Parse do body do Twilio"""
    raw = event.get("body", "")
    if event.get("isBase64Encoded"):
        raw = base64.b64decode(raw).decode("utf-8")
    
    params = urllib.parse.parse_qs(raw, keep_blank_values=True)
    return {k: (v[0] if v else "") for k, v in params.items()}

def _send_whatsapp(to_number: str, message: str):
    """Envia mensagem via Twilio"""
    to = to_number if to_number.startswith("whatsapp:") else f"whatsapp:{to_number}"
    msg = twilio_client.messages.create(
        from_=TWILIO_WHATSAPP_FROM,
        to=to,
        body=message
    )
    return msg.sid

# =========================
# Lambda Handler
# =========================
def lambda_handler(event, context):
    """Handler principal da Lambda"""
    
    # Modo background (execu√ß√£o ass√≠ncrona)
    if event.get("bg"):
        sender = event.get("bg_sender", "")
        user_message = event.get("bg_message", "")
        audio_info = event.get("bg_audio_info")  # Informa√ß√µes do √°udio se houver
        
        try:
            machine = QuestionnaireStateMachine(sender)
            reply = machine.process_message(user_message, audio_info)
            
            # Suporta tanto string √∫nica quanto lista de mensagens
            if isinstance(reply, list):
                for i, msg in enumerate(reply):
                    if msg.strip():
                        _send_whatsapp(sender, msg)
                        # Adiciona pequeno delay entre mensagens para garantir ordem
                        if i < len(reply) - 1:
                            time.sleep(0.5)  # 500ms entre mensagens
            elif reply.strip():
                _send_whatsapp(sender, reply)
            
            return {"statusCode": 200, "body": "ok"}
            
        except Exception as e:
            print(f"[BG Error] {e}")
            try:
                _send_whatsapp(sender, "Desculpe, houve um erro tempor√°rio. Pode repetir sua √∫ltima mensagem?")
            except:
                pass
            return {"statusCode": 200, "body": "error"}
    
    # Modo webhook (Twilio)
    method = event.get("httpMethod")
    
    if method == "POST":
        try:
            data = _parse_twilio_body(event)
            user_message = (data.get("Body") or "").strip()
            sender = (data.get("WaId") or data.get("From", "").replace("whatsapp:", "")).strip()
            
            if not sender:
                return {"statusCode": 400, "body": "Missing sender"}
            
            # Verifica se h√° √°udio na mensagem
            audio_info = None
            num_media = int(data.get("NumMedia", 0))
            
            if num_media > 0:
                # Pega informa√ß√µes do primeiro √°udio
                media_url = data.get("MediaUrl0")
                media_content_type = data.get("MediaContentType0", "audio/ogg")
                
                if media_url:
                    audio_info = {
                        "media_url": media_url,
                        "media_content_type": media_content_type,
                        "num_media": num_media
                    }
                    print(f"[Webhook] √Åudio detectado: {media_url[:50]}..., tipo: {media_content_type}")
                    
                    # Se tem √°udio, ignora o texto (geralmente vem vazio ou com emoji de microfone)
                    user_message = ""
            
            # Invoca execu√ß√£o ass√≠ncrona
            lambda_client.invoke(
                FunctionName=context.invoked_function_arn,
                InvocationType="Event",
                Payload=json.dumps({
                    "bg": True,
                    "bg_sender": sender,
                    "bg_message": user_message,
                    "bg_audio_info": audio_info  # Passa informa√ß√µes do √°udio
                }).encode("utf-8")
            )
            
            # Resposta r√°pida ao Twilio
            twiml = '<?xml version="1.0" encoding="UTF-8"?><Response></Response>'
            return {
                "statusCode": 200,
                "headers": {"Content-Type": "application/xml; charset=utf-8"},
                "body": twiml
            }
            
        except Exception as e:
            print(f"[Webhook Error] {e}")
            return {"statusCode": 500, "body": "error"}
    
    return {"statusCode": 404, "body": "Not found"}
